================================================================
Repopack Output File
================================================================

This file was generated by Repopack on: 2024-11-19T17:33:18.755Z

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This header section
2. Repository structure
3. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
1. This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
2. When processing this file, use the separators and "File:" markers to
  distinguish between different files in the repository.
3. Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repopack's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.



For more information about Repopack, visit: https://github.com/yamadashy/repopack

================================================================
Repository Structure
================================================================
entities/
  optimization_result.py
  optimization_spec.py
optimization/
  constraints.py
  objective_function.py
  optimizer.py
utils/
  math_utils.py
  transformation_utils.py
  validation_utils.py
allocation_plotter.py
budget_allocator.py

================================================================
Repository Files
================================================================

================
File: entities/optimization_result.py
================
# pyre-strict

from dataclasses import dataclass
from typing import Dict, List, Optional

import pandas as pd

import logging

logger = logging.getLogger(__name__)


@dataclass
class AllocationPlots:
    """Container for allocation visualization plots."""

    spend_response_plot: Optional[Dict] = None
    decomposition_plot: Optional[Dict] = None
    response_curves_plot: Optional[Dict] = None
    onepager_plot: Optional[Dict] = None


@dataclass
class OptimizationResult:
    """Contains results from the budget allocation optimization process."""

    dt_optim_out: pd.DataFrame
    main_points: Dict
    nls_mod: Dict
    plots: AllocationPlots
    scenario: str
    usecase: str
    total_budget: float
    skipped_coef0: List[str]
    skipped_constr: List[str]
    no_spend: List[str]

    def __post_init__(self) -> None:
        """Validates the optimization results after initialization."""
        logger.debug("Validating optimization results")
        self._validate_results()

        self.objective_function = None
        # Ensure columns match R implementation
        self.dt_optim_out = self._standardize_column_names(self.dt_optim_out)

    def _validate_results(self) -> None:
        """Performs basic validation of optimization results."""
        if self.dt_optim_out.empty:
            logger.warning("Optimization output DataFrame is empty")

        if not isinstance(self.total_budget, (int, float)) or self.total_budget < 0:
            raise ValueError("Total budget must be a non-negative number")

        if self.scenario not in ["max_response", "target_efficiency"]:
            raise ValueError(f"Invalid scenario '{self.scenario}'. " "Must be 'max_response' or 'target_efficiency'")

    def _standardize_column_names(self, df: pd.DataFrame) -> pd.DataFrame:
        """Standardizes column names to match R implementation."""
        # Map Python column names to R column names
        column_mapping = {
            "channel": "channels",
            "optimal_spend": "optmSpendUnit",
            "initial_spend": "initSpendUnit",
            "response": "optmResponseUnit",
            "spend_share": "optmSpendShareUnit",
            "response_share": "optmResponseShareUnit",
            "roi": "optmRoiUnit",
            "total_spend": "optmSpendUnitTotal",
            "total_response": "optmResponseUnitTotal",
            "response_lift": "optmResponseUnitTotalLift",
        }

        # Rename columns if they exist
        df = df.copy()
        for old_name, new_name in column_mapping.items():
            if old_name in df.columns:
                df = df.rename(columns={old_name: new_name})

        # Calculate additional metrics if needed
        if "optmSpendUnitTotal" not in df.columns:
            df["optmSpendUnitTotal"] = df["optmSpendUnit"].sum()
        if "optmResponseUnitTotal" not in df.columns:
            df["optmResponseUnitTotal"] = df["optmResponseUnit"].sum()
        if "optmResponseUnitTotalLift" not in df.columns:
            df["optmResponseUnitTotalLift"] = df["optmResponseUnit"].sum() / df["initSpendUnit"].sum() - 1

        return df

    def get_optimization_metrics(self) -> Dict[str, float]:
        """Returns key optimization metrics."""
        logger.debug("Calculating optimization metrics")
        df = self.dt_optim_out
        return {
            "total_spend": df["optmSpendUnit"].sum(),
            "total_response": df["optmResponseUnit"].sum(),
            "avg_roi": df["optmResponseUnit"].sum() / df["optmSpendUnit"].sum(),
            "response_lift": df["optmResponseUnitTotalLift"].iloc[0],  # Same for all rows
        }

    def __str__(self) -> str:
        """Returns a string representation of the optimization results."""
        metrics = self.get_optimization_metrics()
        return (
            f"OptimizationResult(scenario={self.scenario}, "
            f"total_spend={metrics['total_spend']:.2f}, "
            f"total_response={metrics['total_response']:.2f}, "
            f"response_lift={metrics['response_lift']:.2%})"
        )

================
File: entities/optimization_spec.py
================
# pyre-strict

from dataclasses import dataclass
from typing import List, Optional, Union
import logging

logger = logging.getLogger(__name__)


@dataclass
class OptimizationSpec:
    """Specification for budget allocation optimization run.

    Attributes:
        scenario: Optimization scenario - either "max_response" or "target_efficiency"
        total_budget: Total marketing budget for all paid channels
        date_range: Date(s) to apply transformations and pick mean spends per channel
        channel_constraints_low: Lower bounds for each paid media variable
        channel_constraints_up: Upper bounds for each paid media variable
        channel_constraint_multiplier: Multiplier for constraint ranges
        max_eval: Maximum iterations for global optimization
        constr_mode: Constraint mode - either "eq" (equality) or "ineq" (inequality)
        target_value: Target ROAS or CPA value for target_efficiency scenario
    """

    scenario: str
    total_budget: Optional[float] = None
    date_range: str = "all"
    channel_constraints_low: Union[float, List[float]] = 0.7
    channel_constraints_up: Union[float, List[float]] = 1.2
    channel_constraint_multiplier: float = 3.0
    max_eval: int = 100000
    constr_mode: str = "eq"
    target_value: Optional[float] = None

    def __post_init__(self) -> None:
        """Validates optimization specifications after initialization."""
        logger.debug("Validating optimization specifications")
        self._validate_specs()

    def _validate_specs(self) -> None:
        """Performs validation of optimization specifications."""
        # Validate scenario
        if self.scenario not in ["max_response", "target_efficiency"]:
            raise ValueError(f"Invalid scenario '{self.scenario}'. Must be 'max_response' or 'target_efficiency'")

        # Validate constraint mode
        if self.constr_mode not in ["eq", "ineq"]:
            raise ValueError(f"Invalid constraint mode '{self.constr_mode}'. Must be 'eq' or 'ineq'")

        # For max_response scenario, total_budget will be set automatically if not provided
        if self.scenario == "max_response":
            if self.total_budget is not None and self.total_budget <= 0:
                raise ValueError("total_budget must be positive when provided")

        # Validate numeric values
        if self.total_budget is not None and self.total_budget <= 0:
            raise ValueError("total_budget must be positive")

        if self.channel_constraint_multiplier <= 0:
            raise ValueError("channel_constraint_multiplier must be positive")

        if self.max_eval <= 0:
            raise ValueError("max_eval must be positive")

        # Validate constraints
        self._validate_constraints()

    def _validate_constraints(self) -> None:
        """Validates constraint values and formats."""
        # Convert single values to lists for consistent handling
        if isinstance(self.channel_constraints_low, (int, float)):
            # If low is single value but up is list, expand low to match length
            if isinstance(self.channel_constraints_up, list):
                self.channel_constraints_low = [float(self.channel_constraints_low)] * len(self.channel_constraints_up)
            else:
                self.channel_constraints_low = [float(self.channel_constraints_low)]

        if isinstance(self.channel_constraints_up, (int, float)):
            # If up is single value but low is list, expand up to match length
            if isinstance(self.channel_constraints_low, list):
                self.channel_constraints_up = [float(self.channel_constraints_up)] * len(self.channel_constraints_low)
            else:
                self.channel_constraints_up = [float(self.channel_constraints_up)]

        # Validate constraint values
        for low in self.channel_constraints_low:
            if low < 0.01:
                raise ValueError("Lower bound constraints must be >= 0.01")

        for up in self.channel_constraints_up:
            if up >= 5:
                raise ValueError("Upper bound constraints must be < 5")

        # Validate constraint relationships
        if len(self.channel_constraints_low) != len(self.channel_constraints_up):
            raise ValueError("channel_constraints_low and channel_constraints_up " "must have the same length")

        for low, up in zip(self.channel_constraints_low, self.channel_constraints_up):
            if low >= up:
                raise ValueError(f"Lower bound constraint ({low}) must be less than " f"upper bound constraint ({up})")

    def _is_valid_date_range(self, date_range: str) -> bool:
        """Checks if a date range string is valid.

        Args:
            date_range: String to validate as date range

        Returns:
            bool indicating if date range is valid
        """
        from datetime import datetime

        try:
            # Try parsing as single date
            datetime.strptime(date_range, "%Y-%m-%d")
            return True
        except ValueError:
            try:
                # Try parsing as date range
                start, end = date_range.split(":")
                datetime.strptime(start, "%Y-%m-%d")
                datetime.strptime(end, "%Y-%m-%d")
                return True
            except ValueError:
                return False

    def get_constraint_bounds(self, num_channels: int) -> tuple[List[float], List[float]]:
        """Returns constraint bounds expanded to match number of channels.

        Args:
            num_channels: Number of media channels

        Returns:
            Tuple of (lower_bounds, upper_bounds) lists
        """
        logger.debug(f"Getting constraint bounds for {num_channels} channels")

        # If single values provided, expand to list
        lower = (
            self.channel_constraints_low * num_channels
            if len(self.channel_constraints_low) == 1
            else self.channel_constraints_low
        )

        upper = (
            self.channel_constraints_up * num_channels
            if len(self.channel_constraints_up) == 1
            else self.channel_constraints_up
        )

        return lower, upper

================
File: optimization/constraints.py
================
# pyre-strict

from typing import Dict, List, Optional, Tuple

import numpy as np


class Constraints:
    """Handles optimization constraints for budget allocation."""

    def __init__(
        self,
        total_budget: Optional[float] = None,
        target_response: Optional[float] = None,
        dep_var_type: str = "revenue",
    ) -> None:
        """Initialize constraint handler."""
        self.total_budget = total_budget
        self.target_response = target_response
        self.dep_var_type = dep_var_type

    def evaluate_equality(
        self,
        x: np.ndarray,
        responses: Optional[np.ndarray] = None,
    ) -> Tuple[float, np.ndarray]:
        """Evaluates equality constraints."""
        # For max_response scenario, use total spend constraint if provided
        # Otherwise use the sum of current spends as the budget constraint
        if self.total_budget is None:
            self.total_budget = np.sum(x)  # Use current total spend as constraint

        constr = np.sum(x) - self.total_budget
        grad = np.ones_like(x)

        return float(constr), grad

    def evaluate_inequality(
        self,
        x: np.ndarray,
        responses: Optional[np.ndarray] = None,
    ) -> Tuple[float, np.ndarray]:
        """Evaluates inequality constraints.

        Args:
            x: Current spend values
            responses: Response values if using target_response constraint

        Returns:
            Tuple of (constraint_value, gradient)
        """
        # Currently same as equality since we use >= constraints
        return self.evaluate_equality(x, responses)

    def check_bounds(
        self,
        x: np.ndarray,
        lower_bounds: np.ndarray,
        upper_bounds: np.ndarray,
    ) -> bool:
        """Checks if values are within bounds.

        Args:
            x: Values to check
            lower_bounds: Minimum allowed values
            upper_bounds: Maximum allowed values

        Returns:
            bool indicating if all values are within bounds
        """
        return bool(np.all(x >= lower_bounds) and np.all(x <= upper_bounds))

    def _constraint_wrapper(self, x: np.ndarray) -> Dict[str, np.ndarray]:
        """Wraps constraints for optimizer.

        Args:
            x: Current spend values

        Returns:
            Dict with constraint value and gradient
        """
        total_spend = np.sum(x)
        print(f"\nEvaluating constraint")
        print(f"Current spend: {x}")
        print(f"Total spend: {total_spend}")
        print(f"Target budget: {self.total_budget}")

        # Scale constraint to improve numerical stability
        scale_factor = self.total_budget if self.total_budget is not None else 1.0

        constr = (total_spend - self.total_budget) / scale_factor
        grad = np.ones_like(x) / scale_factor

        print(f"Constraint value: {constr}")
        print(f"Gradient: {grad}")

        return {"constraints": constr, "jacobian": grad}

================
File: optimization/objective_function.py
================
# pyre-strict

import logging
from typing import Dict, List, Optional, Tuple

import numpy as np
import pandas as pd

logger = logging.getLogger(__name__)


class ObjectiveFunction:
    """Handles response curve calculations and optimization objective functions."""

    def __init__(
        self,
        coef_dict: Dict[str, float],
        alphas_dict: Dict[str, float],
        gammas_dict: Dict[str, float],
        hist_carryover_dict: Dict[str, np.ndarray],
    ) -> None:
        """Initialize objective function calculator.

        Args:
            coef_dict: Channel coefficients from MMM
            alphas_dict: Alpha parameters for hill function
            gammas_dict: Gamma parameters for hill function
            hist_carryover_dict: Historical carryover effect per channel
        """
        self.coef_dict = coef_dict
        self.alphas_dict = alphas_dict
        self.gammas_dict = gammas_dict
        self.hist_carryover_dict = hist_carryover_dict
        logger.debug("Initialized ObjectiveFunction with %d channels", len(coef_dict))

    def calculate_response(self, x: np.ndarray, channel_name: str, get_sum: bool = True) -> float:
        """Calculates response for given spend level."""
        print(f"\nCalculating response for {channel_name}")
        print(f"Input spend: {x}")

        # Get parameters
        coef = self.coef_dict[channel_name]
        alpha = self.alphas_dict[f"{channel_name}_alphas"]
        gamma = self.gammas_dict[f"{channel_name}_gammas"]

        # Add debugging
        print(f"Parameters: coef={coef}, alpha={alpha}, gamma={gamma}")

        # Calculate response
        x_adstocked = x + np.mean(self.hist_carryover_dict[channel_name])
        x_scaled = x_adstocked / gamma
        hill_response = 1 / (1 + (1 / x_scaled) ** alpha)
        response = coef * hill_response

        print(f"Response: {response}")

        return float(np.sum(response)) if get_sum else response

    def calculate_gradient(
        self,
        x: np.ndarray,
        channel_name: str,
        x_hist_carryover: Optional[float] = None,
    ) -> float:
        """Calculates gradient of response curve at given spend level."""
        coef = self.coef_dict[channel_name]
        alpha = self.alphas_dict[f"{channel_name}_alphas"]
        gamma = self.gammas_dict[f"{channel_name}_gammas"]

        if x_hist_carryover is None:
            x_hist_carryover = np.mean(self.hist_carryover_dict[channel_name])

        x_adstocked = x + x_hist_carryover
        x_scaled = x_adstocked / gamma

        # Modified gradient calculation with better numerical stability
        gradient = coef * alpha * x_scaled ** (alpha - 1) / (gamma * (1 + x_scaled**alpha) ** 2)

        return float(np.sum(gradient))

    def calculate_marginal_response(
        self,
        x: float,
        channel_name: str,
        spend_delta: float = 1.0,
    ) -> float:
        """Calculates marginal response for additional spend.

        Args:
            x: Current spend level
            channel_name: Name of channel
            spend_delta: Additional spend amount

        Returns:
            Marginal response value
        """
        response_current = self.calculate_response(x=np.array([x]), channel_name=channel_name, get_sum=False)

        response_new = self.calculate_response(x=np.array([x + spend_delta]), channel_name=channel_name, get_sum=False)

        return float(response_new - response_current)

    def evaluate_total_response(
        self,
        x: np.ndarray,
        channel_names: List[str],
    ) -> Tuple[float, np.ndarray, np.ndarray]:
        """Evaluates total response across all channels.

        Args:
            x: Array of spend values
            channel_names: List of channel names

        Returns:
            Tuple of (total_response, channel_responses, gradients)
        """
        channel_responses = np.zeros(len(channel_names))
        gradients = np.zeros(len(channel_names))

        for i, channel in enumerate(channel_names):
            channel_responses[i] = self.calculate_response(x=np.array([x[i]]), channel_name=channel)
            gradients[i] = self.calculate_gradient(x=np.array([x[i]]), channel_name=channel)

        total_response = np.sum(channel_responses)

        print(f"\nTotal response evaluation:")
        print(f"Spend values: {x}")
        print(f"Channel responses: {channel_responses}")
        print(f"Total response: {total_response}")
        print(f"Gradients: {gradients}")

        return total_response, channel_responses, gradients

================
File: optimization/optimizer.py
================
# pyre-strict

import logging
from typing import Dict, List, Optional, Tuple

import numpy as np
import nevergrad as ng
from scipy import optimize

from .objective_function import ObjectiveFunction
from .constraints import Constraints
from ..entities.optimization_spec import OptimizationSpec

logger = logging.getLogger(__name__)


class Optimizer:
    """Handles optimization for budget allocation."""

    def __init__(
        self,
        objective_function: ObjectiveFunction,
        optimization_spec: OptimizationSpec,
        channel_names: List[str],
        initial_spend: np.ndarray,
        lower_bounds: np.ndarray,
        upper_bounds: np.ndarray,
    ) -> None:
        """Initialize optimizer."""
        self.objective_function = objective_function
        self.optimization_spec = optimization_spec
        self.channel_names = channel_names
        self.initial_spend = initial_spend
        self.lower_bounds = lower_bounds
        self.upper_bounds = upper_bounds
        self.total_budget = (
            self.optimization_spec.total_budget
            if self.optimization_spec.total_budget is not None
            else np.sum(self.initial_spend)
        )
        self.constraints = Constraints(
            total_budget=self.total_budget,
            target_response=self.optimization_spec.target_value,
        )

        logger.debug(
            "Initialized Optimizer with %d channels and %s scenario", len(channel_names), optimization_spec.scenario
        )

    def _objective_wrapper(
        self,
        x: np.ndarray,
        sign: float = -1.0,
    ) -> Dict[str, np.ndarray]:
        """Wraps objective function for optimizer.

        Args:
            x: Spend values
            sign: Direction of optimization (-1 for maximize, 1 for minimize)

        Returns:
            Dict with objective and gradient values
        """
        total_response, channel_responses, gradients = self.objective.evaluate_total_response(x, self.channel_names)

        return {
            "objective": sign * total_response,
            "gradient": sign * gradients,
            "objective_channel": channel_responses,
        }

    def optimize(self) -> Tuple[np.ndarray, Dict, np.ndarray]:
        """Runs optimization."""
        logger.info("Starting optimization")

        # Use log scaling for better numerical stability
        scale = np.mean(np.abs(self.initial_spend))
        x0_scaled = self.initial_spend / scale
        lb_scaled = self.lower_bounds / scale
        ub_scaled = self.upper_bounds / scale
        budget_scaled = self.total_budget / scale

        # Add constraint scaling factor
        constraint_scale = self.total_budget

        # Modified constraints with better scaling
        constraints = [
            {
                "type": "eq" if self.optimization_spec.constr_mode == "eq" else "ineq",
                "fun": lambda x: (np.sum(x * scale) - self.total_budget) / constraint_scale,
                "jac": lambda x: np.ones_like(x) * scale / constraint_scale,
            }
        ]

        # Modified optimization parameters
        options = {
            "maxiter": 1000,
            "ftol": 1e-8,
            "disp": True,
            "iprint": 2,
            "eps": 1e-4,  # Larger step size for finite differences
        }

        # Run optimization with better initial point perturbation
        x0_perturbed = x0_scaled * (1 + np.random.uniform(-0.1, 0.1, len(x0_scaled)))

        result = optimize.minimize(
            fun=lambda x: -self.objective_function.evaluate_total_response(x * scale, self.channel_names)[0],
            x0=x0_perturbed,
            method="SLSQP",
            jac=lambda x: -self.objective_function.evaluate_total_response(x * scale, self.channel_names)[2] * scale,
            bounds=optimize.Bounds(lb_scaled, ub_scaled),
            constraints=constraints,
            options=options,
        )

        # If first attempt doesn't improve, try with different initial points
        if result.fun >= -self.objective_function.evaluate_total_response(self.initial_spend, self.channel_names)[0]:
            best_result = result
            for _ in range(3):
                x0_new = x0_scaled * (1 + np.random.uniform(-0.2, 0.2, len(x0_scaled)))
                temp_result = optimize.minimize(
                    fun=lambda x: -self.objective_function.evaluate_total_response(x * scale, self.channel_names)[0],
                    x0=x0_new,
                    method="SLSQP",
                    jac=lambda x: -self.objective_function.evaluate_total_response(x * scale, self.channel_names)[2]
                    * scale,
                    bounds=optimize.Bounds(lb_scaled, ub_scaled),
                    constraints=constraints,
                    options=options,
                )
                if temp_result.fun < best_result.fun:
                    best_result = temp_result
            result = best_result

        # Unscale the solution
        optimal_spend = result.x * scale

        return optimal_spend, vars(result), self._calculate_responses(optimal_spend)

    def _get_constraints(self, budget_scaled: float) -> List[Dict]:
        """Gets optimization constraints."""
        constraints = [
            {
                "type": "eq" if self.optimization_spec.constr_mode == "eq" else "ineq",
                "fun": lambda x: (np.sum(x) - budget_scaled),
                "jac": lambda x: np.ones_like(x),
            }
        ]

        print("\nConstraint validation:")
        print(f"Budget constraint: sum(x) = {budget_scaled}")
        return constraints

    def _calculate_responses(self, spend_values: np.ndarray) -> np.ndarray:
        """Calculates responses for given spend values.

        Args:
            spend_values: Array of spend values

        Returns:
            Array of response values per channel
        """
        _, channel_responses, _ = self.objective_function.evaluate_total_response(spend_values, self.channel_names)
        return channel_responses

================
File: utils/math_utils.py
================
# pyre-strict
# math_utils.py

from typing import Dict, List, Optional, Union
import numpy as np
import pandas as pd


class MathUtils:
    """Mathematical utilities for budget allocation calculations."""

    @staticmethod
    def calculate_roi(
        response: Union[float, np.ndarray],
        spend: Union[float, np.ndarray],
    ) -> Union[float, np.ndarray]:
        """Calculates ROI (Return on Investment).

        Args:
            response: Response values
            spend: Spend values

        Returns:
            ROI values
        """
        with np.errstate(divide="ignore", invalid="ignore"):
            roi = np.where(spend > 0, response / spend, 0)
        return roi

    @staticmethod
    def calculate_cpa(
        spend: Union[float, np.ndarray],
        conversions: Union[float, np.ndarray],
    ) -> Union[float, np.ndarray]:
        """Calculates CPA (Cost per Acquisition).

        Args:
            spend: Spend values
            conversions: Conversion values

        Returns:
            CPA values
        """
        with np.errstate(divide="ignore", invalid="ignore"):
            cpa = np.where(conversions > 0, spend / conversions, np.inf)
        return cpa

    @staticmethod
    def normalize_values(
        values: np.ndarray,
        method: str = "sum",
    ) -> np.ndarray:
        """Normalizes values using specified method.

        Args:
            values: Values to normalize
            method: Normalization method ("sum", "max", "minmax")

        Returns:
            Normalized values
        """
        if method == "sum":
            return values / np.sum(values)
        elif method == "max":
            return values / np.max(values)
        elif method == "minmax":
            vmin, vmax = np.min(values), np.max(values)
            return (values - vmin) / (vmax - vmin)
        else:
            raise ValueError(f"Unknown normalization method: {method}")

    @staticmethod
    def aggregate_metrics(
        df: pd.DataFrame,
        group_cols: List[str],
        metric_cols: List[str],
        agg_func: str = "mean",
    ) -> pd.DataFrame:
        """Aggregates metrics by groups.

        Args:
            df: Input DataFrame
            group_cols: Columns to group by
            metric_cols: Metric columns to aggregate
            agg_func: Aggregation function

        Returns:
            Aggregated DataFrame
        """
        return df.groupby(group_cols)[metric_cols].agg(agg_func).reset_index()

    @staticmethod
    def calculate_response_lift(
        response_new: Union[float, np.ndarray],
        response_base: Union[float, np.ndarray],
    ) -> Union[float, np.ndarray]:
        """Calculates response lift percentage.

        Args:
            response_new: New response values
            response_base: Base response values

        Returns:
            Lift percentage values
        """
        with np.errstate(divide="ignore", invalid="ignore"):
            lift = np.where(response_base > 0, (response_new / response_base) - 1, 0)
        return lift

================
File: utils/transformation_utils.py
================
# pyre-strict
# transformation_utils.py

from typing import Dict, List, Union, Optional
import numpy as np
import pandas as pd


class TransformationUtils:
    """Utilities for data transformations in budget allocation."""

    @staticmethod
    def calculate_adstock(
        x: np.ndarray,
        theta: float = 0.0,
        adstock_type: str = "geometric",
        shape: Optional[float] = None,
        scale: Optional[float] = None,
    ) -> np.ndarray:
        """Applies adstock transformation to spend data."""
        adstock_type = str(adstock_type).lower()

        if adstock_type == "geometric":
            if theta is None:
                raise ValueError("theta parameter required for geometric adstock")
            return x * theta

        elif adstock_type in ["weibull_cdf", "weibull_pdf", "weibull"]:
            if shape is None or scale is None:
                raise ValueError("shape and scale required for Weibull adstock")
            if adstock_type == "weibull_cdf":
                return 1 - np.exp(-((x / scale) ** shape))
            else:  # weibull_pdf
                return (shape / scale) * (x / scale) ** (shape - 1) * np.exp(-((x / scale) ** shape))
        else:
            raise ValueError(f"Unsupported adstock type: {adstock_type}")

    @staticmethod
    def apply_saturation(
        x: np.ndarray,
        alpha: float,
        gamma: float,
    ) -> np.ndarray:
        """Applies hill function saturation transformation.

        Args:
            x: Input values
            alpha: Hill function alpha parameter
            gamma: Hill function gamma parameter

        Returns:
            Transformed values
        """
        return (1 + (gamma**alpha) / (x**alpha)) ** -1

    @staticmethod
    def get_date_range_indices(
        dates: pd.Series,
        date_spec: str,
    ) -> tuple[int, int]:
        """Gets index range for date specification.

        Args:
            dates: Series of dates
            date_spec: Date range specification

        Returns:
            Tuple of (start_index, end_index)
        """
        if date_spec == "all":
            return 0, len(dates) - 1
        elif date_spec.startswith("last_"):
            n_periods = int(date_spec.split("_")[1])
            return len(dates) - n_periods, len(dates) - 1
        elif ":" in date_spec:
            start_date, end_date = date_spec.split(":")
            start_idx = dates[dates >= pd.Timestamp(start_date)].index[0]
            end_idx = dates[dates <= pd.Timestamp(end_date)].index[-1]
            return start_idx, end_idx
        else:
            try:
                idx = dates[dates == pd.Timestamp(date_spec)].index[0]
                return idx, idx
            except:
                raise ValueError(f"Invalid date specification: {date_spec}")

================
File: utils/validation_utils.py
================
# pyre-strict
# validation_utils.py

import logging
from typing import Dict, List, Optional
import pandas as pd
import numpy as np

logger = logging.getLogger(__name__)


class ValidationUtils:
    """Utilities for input validation in budget allocation."""

    @staticmethod
    def validate_spend_data(
        spends: pd.DataFrame,
        paid_media_vars: List[str],
    ) -> None:
        """Validates media spend data.

        Args:
            spends: DataFrame containing spend data
            paid_media_vars: List of media variable names

        Raises:
            ValueError: If validation fails
        """
        if not all(var in spends.columns for var in paid_media_vars):
            missing = set(paid_media_vars) - set(spends.columns)
            raise ValueError(f"Missing spend variables: {missing}")

        if (spends[paid_media_vars] < 0).any().any():
            raise ValueError("Negative spend values found")

    @staticmethod
    def validate_constraints(
        channel_constraints_low: np.ndarray,
        channel_constraints_up: np.ndarray,
        channel_names: List[str],
    ) -> None:
        """Validates channel constraints.

        Args:
            channel_constraints_low: Lower bounds
            channel_constraints_up: Upper bounds
            channel_names: Channel names

        Raises:
            ValueError: If validation fails
        """
        if len(channel_constraints_low) != len(channel_names):
            raise ValueError("Lower constraints must match number of channels")

        if len(channel_constraints_up) != len(channel_names):
            raise ValueError("Upper constraints must match number of channels")

        if any(channel_constraints_low < 0.01):
            raise ValueError("Lower bounds must be >= 0.01")

        if any(channel_constraints_up >= 5):
            raise ValueError("Upper bounds must be < 5")

        if any(channel_constraints_low >= channel_constraints_up):
            raise ValueError("Lower bounds must be less than upper bounds")

    @staticmethod
    def verify_budget(
        total_budget: float,
        historical_spend: float,
        window_size: int,
    ) -> None:
        """Verifies budget feasibility.

        Args:
            total_budget: Proposed total budget
            historical_spend: Historical spend amount
            window_size: Number of periods

        Raises:
            ValueError: If budget is invalid
        """
        if total_budget <= 0:
            raise ValueError("Total budget must be positive")

        budget_per_period = total_budget / window_size
        hist_per_period = historical_spend / window_size

        if budget_per_period < 0.1 * hist_per_period:
            logger.warning(
                "Budget per period (%.2f) is <10%% of historical spend (%.2f)", budget_per_period, hist_per_period
            )

================
File: allocation_plotter.py
================
# allocation_plotter.py

from typing import Dict, List, Optional, Tuple
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib.gridspec import GridSpec
from robyn.new_allocator.optimization.objective_function import ObjectiveFunction
from matplotlib.gridspec import GridSpec


class AllocationPlotter:
    """Creates visualization plots for budget allocation results."""

    def __init__(self, dark_mode: bool = False):
        """Initialize plotter with style settings."""
        self.dark_mode = dark_mode
        self._set_style()

    def _set_style(self):
        """Sets plotting style."""
        # plt.style.use("seaborn")
        # if self.dark_mode:
        #     plt.style.use("dark_background")

        # Custom color palette
        self.colors = {
            "primary": "#59B3D2",
            "secondary": "#E5586E",
            "tertiary": "#38618C",
            "initial": "grey",
            "bounded": "steelblue",
            "unbounded": "darkgoldenrod4",
        }

    def create_onepager(
        self,
        dt_optim_out: pd.DataFrame,
        plot_data: Dict[str, Dict[str, np.ndarray]],
        scenario: str,
        date_range: Tuple[str, str],
        interval_type: str = "Week",
        figsize: Tuple[int, int] = (15, 20),
    ) -> plt.Figure:
        """Creates allocation one-pager plot.

        Args:
            dt_optim_out: Allocation results DataFrame
            plot_data: Response curves data from _prepare_response_curves_data
            scenario: Optimization scenario used
            date_range: Tuple of (start_date, end_date)
            interval_type: Time interval type (e.g. "Week")
            figsize: Figure size tuple

        Returns:
            Matplotlib figure containing the one-pager plots
        """
        # Create figure with grid
        fig = plt.figure(figsize=figsize)
        gs = GridSpec(3, 1, height_ratios=[1, 2, 2], hspace=0.3)

        # Create subplots
        ax1 = fig.add_subplot(gs[0])  # Total Budget Optimization
        ax2 = fig.add_subplot(gs[1])  # Budget Allocation per Media
        ax3 = fig.add_subplot(gs[2])  # Response Curves

        # Plot total budget optimization
        self._plot_total_budget_optimization(ax1, dt_optim_out, scenario)

        # Plot budget allocation
        self._plot_budget_allocation(ax2, dt_optim_out, interval_type)

        # Plot response curves
        self._plot_response_curves(ax3, plot_data, dt_optim_out)

        # Add title and metadata
        fig.suptitle(
            f"Budget Allocation One-pager\n" f"Date Range: {date_range[0]} to {date_range[1]}", fontsize=14, y=0.95
        )

        return fig

    def _plot_total_budget_optimization(self, ax: plt.Axes, dt_optim_out: pd.DataFrame, scenario: str) -> None:
        """Plots total budget optimization results."""
        # Calculate totals
        init_spend_total = dt_optim_out["initSpendUnit"].sum()
        init_response_total = dt_optim_out["initResponseUnit"].sum()
        optm_spend_total = dt_optim_out["optmSpendUnit"].sum()
        optm_response_total = dt_optim_out["optmResponseUnit"].sum()

        # Prepare data
        metrics = pd.DataFrame(
            {
                "Metric": ["Total Spend", "Total Response"],
                "Initial": [init_spend_total, init_response_total],
                "Optimized": [optm_spend_total, optm_response_total],
            }
        )

        # Create grouped bar plot
        x = np.arange(len(metrics["Metric"]))
        width = 0.35

        ax.bar(x - width / 2, metrics["Initial"], width, label="Initial", color=self.colors["initial"])
        ax.bar(x + width / 2, metrics["Optimized"], width, label="Optimized", color=self.colors["bounded"])

        # Add value labels
        for i in x:
            ax.text(i - width / 2, metrics["Initial"][i], f'{metrics["Initial"][i]:,.0f}', ha="center", va="bottom")
            ax.text(
                i + width / 2, metrics["Optimized"][i], f'{metrics["Optimized"][i]:,.0f}', ha="center", va="bottom"
            )

        # Customize plot
        ax.set_xticks(x)
        ax.set_xticklabels(metrics["Metric"])
        ax.set_title("Total Budget Optimization Result")
        ax.legend()

    def _plot_budget_allocation(self, ax: plt.Axes, dt_optim_out: pd.DataFrame, interval_type: str) -> None:
        """Plots budget allocation per media variable."""
        # Prepare data for plotting
        plot_data = pd.DataFrame(
            {
                "Channel": dt_optim_out["channels"],
                "Initial Share": dt_optim_out["initSpendShare"] * 100,
                "Optimized Share": dt_optim_out["optmSpendShareUnit"] * 100,
                "Initial Spend": dt_optim_out["initSpendUnit"],
                "Optimized Spend": dt_optim_out["optmSpendUnit"],
            }
        )

        # Create horizontal bar plot
        y_pos = np.arange(len(plot_data["Channel"]))

        # Plot share bars
        ax.barh(
            y_pos - 0.2,
            plot_data["Initial Share"],
            height=0.3,
            color=self.colors["initial"],
            alpha=0.7,
            label="Initial Share (%)",
        )
        ax.barh(
            y_pos + 0.2,
            plot_data["Optimized Share"],
            height=0.3,
            color=self.colors["bounded"],
            alpha=0.7,
            label="Optimized Share (%)",
        )

        # Add spend values as text
        for i, row in plot_data.iterrows():
            ax.text(row["Initial Share"], i - 0.2, f'${row["Initial Spend"]:,.0f}', va="center", ha="left")
            ax.text(row["Optimized Share"], i + 0.2, f'${row["Optimized Spend"]:,.0f}', va="center", ha="left")

        # Customize plot
        ax.set_yticks(y_pos)
        ax.set_yticklabels(plot_data["Channel"])
        ax.set_xlabel("Share of Budget (%)")
        ax.set_title(f"Budget Allocation per Paid Media Variable per {interval_type}")
        ax.legend(loc="upper right")

    def _plot_response_curves(self, ax: plt.Axes, plot_data: Dict, dt_optim_out: pd.DataFrame) -> None:
        """Plots response curves for each channel."""
        # Plot response curves for each channel
        for channel, data in plot_data.items():
            # Plot response curve
            ax.plot(data["spend"], data["response"], label=channel, alpha=0.7)

            # Plot current and optimized points
            current = dt_optim_out[dt_optim_out["channels"] == channel].iloc[0]
            ax.scatter(
                current["initSpendUnit"], current["initResponseUnit"], marker="o", s=100, label=f"{channel} (Current)"
            )
            ax.scatter(
                current["optmSpendUnit"],
                current["optmResponseUnit"],
                marker="*",
                s=100,
                label=f"{channel} (Optimized)",
            )

        # Customize plot
        ax.set_xlabel("Spend")
        ax.set_ylabel("Response")
        ax.set_title("Simulated Response Curves per Channel")
        ax.legend(bbox_to_anchor=(1.05, 1), loc="upper left")

    def save_plot(self, fig: plt.Figure, filename: str, dpi: int = 300) -> None:
        """Saves plot to file."""
        fig.savefig(filename, dpi=dpi, bbox_inches="tight")
        plt.close(fig)

    def _prepare_response_curves_data(
        self, channels: List[str], allocation_df: pd.DataFrame, objective_function: ObjectiveFunction
    ) -> Dict[str, Dict[str, np.ndarray]]:
        """Prepares data for response curves plotting.

        Args:
            channels: List of media channel names
            allocation_df: DataFrame containing allocation results
            objective_function: Configured ObjectiveFunction instance

        Returns:
            Dictionary containing spend and response data for each channel
        """
        plot_data = {}

        for channel in channels:
            # Get channel's current and optimal spend
            channel_data = allocation_df[allocation_df["channels"] == channel].iloc[0]
            current_spend = channel_data["initSpendUnit"]
            optimal_spend = channel_data["optmSpendUnit"]

            # Create spend range for curve
            max_spend = max(current_spend, optimal_spend) * 1.5
            spend_range = np.linspace(0, max_spend, 100)

            # Calculate responses
            responses = [
                objective_function.calculate_response(x=np.array([spend]), channel_name=channel, get_sum=True)
                for spend in spend_range
            ]

            plot_data[channel] = {"spend": spend_range, "response": np.array(responses)}

        return plot_data

================
File: budget_allocator.py
================
# pyre-strict

import logging
from typing import Dict, List, Optional, Union, Tuple

import numpy as np
import pandas as pd
from dataclasses import asdict


from robyn.data.entities.enums import AdstockType
from .optimization.optimizer import Optimizer
from .optimization.objective_function import ObjectiveFunction
from .entities.optimization_result import OptimizationResult, AllocationPlots
from .entities.optimization_spec import OptimizationSpec
from .utils.validation_utils import ValidationUtils
from .utils.transformation_utils import TransformationUtils
from .utils.math_utils import MathUtils
from ..data.entities.mmmdata import MMMData
from ..modeling.entities.modeloutputs import ModelOutputs
from ..data.entities.hyperparameters import Hyperparameters
from .allocation_plotter import AllocationPlotter

logger = logging.getLogger(__name__)


class BudgetAllocator:
    """Main class for budget allocation optimization."""

    def __init__(
        self,
        input_collect: MMMData,
        output_collect: ModelOutputs,
        select_model: str,
        hyperparameters: Hyperparameters,  # Add this parameter
    ) -> None:
        """Initialize budget allocator.

        Args:
            input_collect: MMM input data and parameters
            output_collect: MMM model outputs
            select_model: Selected model ID
            hyperparameters: Model hyperparameters
        """
        self.input_collect = input_collect
        self.output_collect = output_collect
        self.select_model = select_model
        self.hyperparameters = hyperparameters  # Store hyperparameters
        self.paid_media_vars = input_collect.mmmdata_spec.paid_media_spends

        # Validate inputs
        self._validate_inputs()
        logger.info(f"Initialized BudgetAllocator with model {select_model}")

    def _validate_inputs(self) -> None:
        """Validates input data and model selection."""
        if not self.paid_media_vars:
            raise ValueError("No paid media variables specified")

        if self.select_model not in self.output_collect.all_result_hyp_param.sol_id.unique():
            raise ValueError(f"Model {self.select_model} not found in results")

        ValidationUtils.validate_spend_data(self.input_collect.data, self.paid_media_vars)

    def _get_model_params(self) -> Dict:
        """Extracts model parameters for selected model."""
        print("Extracting model parameters...")
        model_params = (
            self.output_collect.all_result_hyp_param[
                self.output_collect.all_result_hyp_param.sol_id == self.select_model
            ]
            .iloc[0]
            .to_dict()
        )

        # Add debug information
        print("\nModel parameters:")
        print(f"Total parameters: {len(model_params)}")
        print("Parameter names:", list(model_params.keys()))
        print("\nPaid media variables:", self.paid_media_vars)

        # Detect adstock type from parameters
        sample_channel = self.paid_media_vars[0]
        if f"{sample_channel}_thetas" in model_params:
            actual_adstock_type = "geometric"
        elif f"{sample_channel}_S_shapes" in model_params:
            actual_adstock_type = "weibull"
        else:
            actual_adstock_type = str(self.hyperparameters.adstock).lower()

        print(f"\nDetected adstock type: {actual_adstock_type}")

        # Validate parameters exist for each channel
        for channel in self.paid_media_vars:
            if actual_adstock_type == "geometric":
                param_name = f"{channel}_thetas"
                required_params = [param_name]
            else:  # weibull
                param_names = [f"{channel}_S_shapes", f"{channel}_S_scales"]
                required_params = param_names

            missing_params = [p for p in required_params if p not in model_params]

            if missing_params:
                raise KeyError(
                    f"Missing required parameters for channel {channel}: {missing_params}"
                    f"\nAvailable parameters: {list(model_params.keys())}"
                )

        # Store detected adstock type for use in other methods
        self._actual_adstock_type = actual_adstock_type
        return model_params

    def _get_response_coefficients(self) -> Dict[str, float]:
        """Gets response coefficients for each channel."""
        coef_data = self.output_collect.all_x_decomp_agg[
            (self.output_collect.all_x_decomp_agg.sol_id == self.select_model)
            & (self.output_collect.all_x_decomp_agg.rn.isin(self.paid_media_vars))
        ]
        return dict(zip(coef_data.rn, coef_data.coef))

    def _prepare_optimization_inputs(
        self,
        optimization_spec: OptimizationSpec,
    ) -> Dict:
        """Prepares inputs for optimization."""
        print("\nPreparing optimization inputs with spec:")
        print(optimization_spec)

        # Get date range indices
        start_idx, end_idx = TransformationUtils.get_date_range_indices(
            self.input_collect.data[self.input_collect.mmmdata_spec.date_var], optimization_spec.date_range
        )
        print(f"\nDate range indices: {start_idx} to {end_idx}")

        # Get historical spend data
        hist_spend = self.input_collect.data.iloc[start_idx : end_idx + 1][self.paid_media_vars]
        print("\nHistorical spend head:")
        print(hist_spend.head())

        # Calculate initial spend values (mean spend for each channel)
        initial_spend = hist_spend.mean().values
        print(f"\nInitial spend values:\n{initial_spend}")

        # If total_budget is not provided, use historical total spend
        if optimization_spec.total_budget is None:
            total_budget = hist_spend.sum().sum()
            logger.info(f"Using historical total spend as budget: {total_budget}")
        else:
            total_budget = optimization_spec.total_budget

        # Get model parameters
        model_params = self._get_model_params()
        print(f"\nAdstock type: {self.hyperparameters.adstock}")

        # Get response coefficients
        coef_dict = self._get_response_coefficients()
        print("\nResponse coefficients:")
        print(coef_dict)

        # Calculate constraint bounds
        lower_bounds, upper_bounds = self._calculate_constraint_bounds(
            initial_spend=initial_spend,
            constraints_low=optimization_spec.channel_constraints_low,
            constraints_up=optimization_spec.channel_constraints_up,
            multiplier=optimization_spec.channel_constraint_multiplier,
        )
        print("\nConstraint bounds:")
        print(f"Lower: {lower_bounds}")
        print(f"Upper: {upper_bounds}")

        # Calculate historical carryover effects
        hist_carryover = self._calculate_historical_carryover(hist_spend, model_params)

        return {
            "initial_spend": initial_spend,
            "total_budget": total_budget,  # Add this line
            "model_params": model_params,
            "coef_dict": coef_dict,
            "lower_bounds": lower_bounds,
            "upper_bounds": upper_bounds,
            "hist_carryover": hist_carryover,
            "hist_spend": hist_spend,
        }

    def _calculate_historical_carryover(
        self,
        hist_spend: pd.DataFrame,
        model_params: Dict,
    ) -> Dict[str, np.ndarray]:
        """Calculates historical carryover effects."""
        print("\nCalculating historical carryover...")
        hist_carryover = {}
        adstock_type = getattr(self, "_actual_adstock_type", "geometric")  # Default to geometric if not set
        print(f"Using adstock type: {adstock_type}")

        for channel in self.paid_media_vars:
            print(f"\nProcessing channel: {channel}")
            try:
                if adstock_type == "geometric":
                    theta = model_params[f"{channel}_thetas"]
                    print(f"Using theta value: {theta}")
                    carryover = TransformationUtils.calculate_adstock(
                        hist_spend[channel].values, theta=theta, adstock_type="geometric"
                    )
                else:  # weibull
                    shape = model_params[f"{channel}_S_shapes"]
                    scale = model_params[f"{channel}_S_scales"]

                    carryover = TransformationUtils.calculate_adstock(
                        hist_spend[channel].values,
                        theta=0.0,  # dummy value for non-geometric
                        adstock_type="weibull",
                        shape=shape,
                        scale=scale,
                    )
                hist_carryover[channel] = carryover
                print(f"Successfully calculated carryover for {channel}")

            except KeyError as e:
                print(f"Error: Missing parameter for channel {channel}: {str(e)}")
                print(f"Available parameters: {list(model_params.keys())}")
                raise

        return hist_carryover

    def run_allocation(
        self,
        scenario: str = "max_response",
        total_budget: Optional[float] = None,
        date_range: str = "all",
        channel_constraints_low: Union[float, List[float]] = 0.7,
        channel_constraints_up: Union[float, List[float]] = 1.2,
        channel_constraint_multiplier: float = 3.0,
        max_eval: int = 100000,
        constr_mode: str = "eq",
        target_value: Optional[float] = None,
    ) -> OptimizationResult:
        """Runs budget allocation optimization.

        Args:
            scenario: Optimization scenario ("max_response" or "target_efficiency")
            total_budget: Total marketing budget (optional)
            date_range: Date range for allocation
            channel_constraints_low: Lower bounds for channel constraints
            channel_constraints_up: Upper bounds for channel constraints
            channel_constraint_multiplier: Multiplier for constraint ranges
            max_eval: Maximum optimization iterations
            constr_mode: Constraint mode ("eq" or "ineq")
            target_value: Target value for efficiency scenario

        Returns:
            OptimizationResult object containing allocation results
        """
        logger.info(f"Starting budget allocation with scenario: {scenario}")

        print("\nRunning budget allocation")
        print(f"Scenario: {scenario}")
        print(f"Channel constraints: [{channel_constraints_low}, {channel_constraints_up}]")

        # Input validation
        if len(self.paid_media_vars) < 2:
            raise ValueError("Need at least 2 paid media channels")

        if total_budget is not None and total_budget <= 0:
            raise ValueError("Total budget must be positive")

        # Create optimization specification
        optimization_spec = OptimizationSpec(
            scenario=scenario,
            total_budget=total_budget,
            date_range=date_range,
            channel_constraints_low=channel_constraints_low,
            channel_constraints_up=channel_constraints_up,
            channel_constraint_multiplier=channel_constraint_multiplier,
            max_eval=max_eval,
            constr_mode=constr_mode,
            target_value=target_value,
        )

        print("\nPreparing optimization inputs with spec:")
        print(optimization_spec)

        # Prepare optimization inputs
        optim_inputs = self._prepare_optimization_inputs(optimization_spec)

        # Use historical total spend if no budget specified
        if total_budget is None:
            total_budget = np.sum(optim_inputs["hist_spend"])
            logger.info(f"Using historical total spend as budget: {total_budget}")

        # Create objective function
        self.objective_function = ObjectiveFunction(
            coef_dict=optim_inputs["coef_dict"],
            alphas_dict=optim_inputs["model_params"],
            gammas_dict=optim_inputs["model_params"],
            hist_carryover_dict=optim_inputs["hist_carryover"],
        )

        # Calculate initial response for comparison
        initial_response = self.objective_function.evaluate_total_response(
            optim_inputs["initial_spend"], self.paid_media_vars
        )[0]

        # Create and run optimizer
        optimizer = Optimizer(
            objective_function=self.objective_function,
            optimization_spec=optimization_spec,
            channel_names=self.paid_media_vars,
            initial_spend=optim_inputs["initial_spend"],
            lower_bounds=optim_inputs["lower_bounds"],
            upper_bounds=optim_inputs["upper_bounds"],
        )

        optimal_spend, optimization_result, channel_responses = optimizer.optimize()

        # Validate optimization results
        final_response = self.objective_function.evaluate_total_response(optimal_spend, self.paid_media_vars)[0]

        improvement = (final_response - initial_response) / abs(initial_response)

        if improvement < 0.001:  # Less than 0.1% improvement
            logger.warning(
                f"Very small improvement in optimization: {improvement:.2%}. "
                "Consider adjusting constraints or optimization parameters."
            )

        # Create results DataFrame
        dt_optim_out = pd.DataFrame(
            {
                "channels": self.paid_media_vars,
                "initSpendUnit": optim_inputs["initial_spend"],
                "optmSpendUnit": optimal_spend,
                "optmResponseUnit": channel_responses,
                "optmSpendShareUnit": optimal_spend / optimal_spend.sum(),
                "optmResponseShareUnit": channel_responses / channel_responses.sum(),
                "initSpendShare": optim_inputs["initial_spend"] / optim_inputs["initial_spend"].sum(),
                "initResponseUnit": self.objective_function.evaluate_total_response(
                    optim_inputs["initial_spend"], self.paid_media_vars
                )[1],
            }
        )

        # Calculate total metrics
        dt_optim_out["optmSpendUnitTotal"] = dt_optim_out["optmSpendUnit"].sum()
        dt_optim_out["optmResponseUnitTotal"] = dt_optim_out["optmResponseUnit"].sum()
        dt_optim_out["initResponseUnitTotal"] = dt_optim_out["initResponseUnit"].sum()
        dt_optim_out["optmResponseUnitTotalLift"] = (
            dt_optim_out["optmResponseUnitTotal"] / dt_optim_out["initResponseUnitTotal"] - 1
        )

        # Calculate ROI metrics
        if self.input_collect.dep_var_type == "revenue":
            dt_optim_out["optmRoiUnit"] = dt_optim_out["optmResponseUnit"] / dt_optim_out["optmSpendUnit"]
            dt_optim_out["initRoiUnit"] = dt_optim_out["initResponseUnit"] / dt_optim_out["initSpendUnit"]
        else:  # conversion/CPA case
            dt_optim_out["optmCpaUnit"] = dt_optim_out["optmSpendUnit"] / dt_optim_out["optmResponseUnit"]
            dt_optim_out["initCpaUnit"] = dt_optim_out["initSpendUnit"] / dt_optim_out["initResponseUnit"]

        # Create result object
        result = OptimizationResult(
            dt_optim_out=dt_optim_out,
            main_points={},  # Can be expanded if needed
            nls_mod=optimization_result,
            plots=AllocationPlots(),
            scenario=scenario,
            usecase=self._determine_usecase(date_range),
            total_budget=total_budget,
            skipped_coef0=[],  # Add if implementing coefficient filtering
            skipped_constr=[],  # Add if implementing constraint filtering
            no_spend=[],  # Add if implementing zero spend detection
        )

        logger.info("Budget allocation completed successfully")
        return result

    # Example usage in budget_allocator.py

    def _create_allocation_plots(
        self,
        metrics: Dict,
        optimization_spec: OptimizationSpec,
        hist_spend: pd.DataFrame,
    ) -> AllocationPlots:
        """Creates visualization plots for allocation results."""
        plotter = AllocationPlotter()

        # Create response curves data
        plot_data = self._prepare_response_curves_data(
            self.paid_media_vars, metrics["allocation_df"], self.objective_function
        )

        # Create and save one-pager
        fig = plotter.create_onepager(
            dt_optim_out=metrics["allocation_df"],
            plot_data=plot_data,
            scenario=optimization_spec.scenario,
            date_range=(hist_spend.index[0], hist_spend.index[-1]),
            interval_type="Week",  # Or from your input parameters
        )

        if self.export:
            plotter.save_plot(fig, f"{self.output_dir}/allocation_onepager.png")

        return AllocationPlots(onepager_plot=fig)

    def _prepare_response_curves_data(
        self, channels: List[str], allocation_df: pd.DataFrame, objective_function: ObjectiveFunction
    ) -> Dict:
        """Prepares data for response curves plotting.

        Args:
            channels: List of media channel names
            allocation_df: DataFrame containing allocation results
            objective_function: Configured ObjectiveFunction instance

        Returns:
            Dictionary containing spend and response curves data for each channel
        """
        plot_data = {}

        for channel in channels:
            # Get channel's current and optimal spend
            current_spend = allocation_df[allocation_df["channels"] == channel]["initSpendUnit"].iloc[0]
            optimal_spend = allocation_df[allocation_df["channels"] == channel]["optmSpendUnit"].iloc[0]

            # Create spend range for curve
            max_spend = max(current_spend, optimal_spend) * 1.5
            spend_range = np.linspace(0, max_spend, 100)

            # Calculate responses
            responses = [
                objective_function.calculate_response(x=np.array([spend]), channel_name=channel)
                for spend in spend_range
            ]

            plot_data[channel] = {
                "spend": spend_range,
                "response": responses,
                "current_point": (
                    current_spend,
                    objective_function.calculate_response(x=np.array([current_spend]), channel_name=channel),
                ),
                "optimal_point": (
                    optimal_spend,
                    objective_function.calculate_response(x=np.array([optimal_spend]), channel_name=channel),
                ),
            }

        return plot_data

    def _calculate_allocation_metrics(
        self,
        optimal_spend: np.ndarray,
        initial_spend: np.ndarray,
        channel_responses: np.ndarray,
        hist_spend: pd.DataFrame,
    ) -> Dict:
        """Calculates metrics for optimization results.

        Args:
            optimal_spend: Optimized spend values
            initial_spend: Initial spend values
            channel_responses: Channel response values
            hist_spend: Historical spend data

        Returns:
            Dictionary of calculated metrics
        """
        # Identify channels to skip
        coef_dict = self._get_response_coefficients()
        skipped_coef0 = [channel for channel, coef in coef_dict.items() if coef == 0]

        skipped_constr = [
            channel
            for channel, spend in zip(self.paid_media_vars, optimal_spend)
            if spend == 0 and channel not in skipped_coef0
        ]

        no_spend = [channel for channel in self.paid_media_vars if hist_spend[channel].sum() == 0]

        # Calculate allocation metrics
        allocation_df = pd.DataFrame(
            {
                "channel": self.paid_media_vars,
                "optimal_spend": optimal_spend,
                "initial_spend": initial_spend,
                "response": channel_responses,
                "spend_share": optimal_spend / optimal_spend.sum(),
                "response_share": channel_responses / channel_responses.sum(),
                "roi": MathUtils.calculate_roi(channel_responses, optimal_spend),
            }
        )

        # Calculate main points for response curves
        main_points = {
            "initial": {"spend": initial_spend, "response": channel_responses},
            "optimal": {"spend": optimal_spend, "response": channel_responses},
        }

        return {
            "allocation_df": allocation_df,
            "main_points": main_points,
            "total_spend": optimal_spend.sum(),
            "total_response": channel_responses.sum(),
            "skipped_coef0": skipped_coef0,
            "skipped_constr": skipped_constr,
            "no_spend": no_spend,
        }

    def _determine_usecase(self, date_range: str) -> str:
        """Determines optimization use case based on date range.

        Args:
            date_range: Date range specification

        Returns:
            Use case description
        """
        if date_range == "all":
            return "all_historical"
        elif date_range.startswith("last"):
            return f"last_{date_range.split('_')[1]}_periods"
        else:
            return "custom_date_range"

    def _calculate_constraint_bounds(
        self,
        initial_spend: np.ndarray,
        constraints_low: Union[float, List[float]],
        constraints_up: Union[float, List[float]],
        multiplier: float = 3.0,
    ) -> Tuple[np.ndarray, np.ndarray]:
        """Calculates lower and upper bounds for constraints.

        Args:
            initial_spend: Initial spend values
            constraints_low: Lower constraint percentages
            constraints_up: Upper constraint percentages
            multiplier: Multiplier for constraint ranges

        Returns:
            Tuple of (lower_bounds, upper_bounds) arrays
        """
        logger.debug("Calculating constraint bounds")

        # Convert inputs to numpy arrays
        initial_spend = np.array(initial_spend)

        # Convert single values to arrays if needed
        if isinstance(constraints_low, (int, float)):
            constraints_low = np.full_like(initial_spend, constraints_low, dtype=float)
        else:
            constraints_low = np.array(constraints_low, dtype=float)

        if isinstance(constraints_up, (int, float)):
            constraints_up = np.full_like(initial_spend, constraints_up, dtype=float)
        else:
            constraints_up = np.array(constraints_up, dtype=float)

        # Calculate bounds
        lower_bounds = initial_spend * constraints_low
        upper_bounds = initial_spend * constraints_up

        logger.debug(f"Initial bounds: {lower_bounds} to {upper_bounds}")
        logger.debug(f"Using multiplier: {multiplier}")

        # Apply constraint multiplier
        lower_extension = 1 - (1 - constraints_low) * multiplier
        lower_bounds_ext = np.where(lower_extension < 0, np.zeros_like(initial_spend), initial_spend * lower_extension)

        upper_extension = 1 + (constraints_up - 1) * multiplier
        upper_bounds_ext = np.where(
            upper_extension < 0, initial_spend * constraints_up * multiplier, initial_spend * upper_extension
        )

        return lower_bounds_ext, upper_bounds_ext
