================================================================
Repopack Output File
================================================================

This file was generated by Repopack on: 2024-08-29T13:44:53.426Z

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This header section
2. Repository structure
3. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
1. This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
2. When processing this file, use the separators and "File:" markers to
  distinguish between different files in the repository.
3. Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repopack's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.



For more information about Repopack, visit: https://github.com/yamadashy/repopack

================================================================
Repository Structure
================================================================
demo/
  modeling/
    README.md
existing-code/
  allocator.R/
    README.md
  clusters.R/
    README.md
  inputs.R/
    README.md
  model.R/
    README.md
  outputs.R/
    README.md
  pareto.R/
    README.md
  transformations.R/
    README.md
overview/
  README.md

================================================================
Repository Files
================================================================

================
File: demo/modeling/README.md
================
### Modeling Component

```mermaid
graph TD
    A[Start] --> B[robyn_inputs]
    B --> C[robyn_run]
    C --> D[robyn_outputs]
    D --> E[robyn_allocator]
    E --> F[End]

    subgraph "Main R Files"
        R1[inputs.R]
        R2[model.R]
        R3[outputs.R]
        R4[allocator.R]
    end

    B -.-> R1
    C -.-> R2
    D -.-> R3
    E -.-> R4

    subgraph "Key Supporting Files"
        S1[transformations.R]
        S2[pareto.R]
        S3[clusters.R]
    end

    R1 -.-> S1
    R2 -.-> S1
    R3 -.-> S2
    R3 -.-> S3
```

#### R reference files

================
File: existing-code/allocator.R/README.md
================
### Flowchart
```mermaid

graph TD
    A[Start: robyn_allocator function] --> B[Process input parameters]
    B --> C[Check allocator constraints]
    C --> D[Prepare data for allocation]
    D --> E[Set up optimization problem]
    E --> F[Run optimization algorithm]

    subgraph "Optimization Loop"
        F1[Calculate objective function]
        F2[Apply constraints]
        F3[Update allocation]
    end

    F --> F1 --> F2 --> F3
    F3 -->|Not converged| F1
    F3 -->|Converged| G[Process optimization results]

    G --> H[Calculate allocation metrics]
    H --> I[Generate response curves]
    I --> J[Prepare output data]
    J --> K[Create allocation plots]
    K --> L[End: Return AllocatorCollect]

```

### Class Diagram
```mermaid
classDiagram
    class robyn_allocator {
        +InputCollect
        +OutputCollect
        +select_model
        +scenario
        +channel_constr_low
        +channel_constr_up
        +export
        +allocate()
    }

    class AllocatorCollect {
        +dt_optimOut
        +plots
        +scenario
        +total_budget
        +main_plot
        +response_curves
    }

    class optimization_functions {
        +eval_f()
        +eval_g_eq()
        +eval_g_ineq()
        +fx_objective()
        +fx_gradient()
    }

    class allocation_plots {
        +plot_allocation_results()
        +plot_response_curves()
    }

    robyn_allocator --> AllocatorCollect : produces
    robyn_allocator --> optimization_functions : uses
    robyn_allocator --> allocation_plots : uses
```

================
File: existing-code/clusters.R/README.md
================
### Flowchart

```mermaid
graph TD
    A[Start: robyn_clusters function] --> B[Check input parameters]
    B --> C[Prepare data for clustering]
    C --> D{Cluster by performance or hyperparameters?}
    D -->|Performance| E[Prepare performance data]
    D -->|Hyperparameters| F[Prepare hyperparameter data]
    E --> G[Run clustering algorithm]
    F --> G
    G --> H[Calculate in-cluster confidence intervals]
    H --> I[Generate cluster plots]
    I --> J[Prepare output data]
    J --> K[End: Return clustering results]

    subgraph "Clustering Algorithm"
        G1[Calculate distance matrix]
        G2[Determine optimal number of clusters]
        G3[Apply k-means clustering]
    end
    G --> G1 --> G2 --> G3
```

### Class Diagram
```mermaid
classDiagram
    class robyn_clusters {
        +input : OutputCollect
        +dep_var_type : str
        +cluster_by : str
        +all_media : list
        +k : int or "auto"
        +limit : int
        +weights : list
        +dim_red : str
        +quiet : bool
        +export : bool
        +seed : int
        +prepare_data()
        +run_clustering()
        +calculate_confidence_intervals()
        +generate_plots()
        +format_output()
    }

    class ClusterResults {
        +data : DataFrame
        +df_cluster_ci : DataFrame
        +n_clusters : int
        +boot_n : int
        +sim_n : int
        +errors_weights : list
        +wss : Plot
        +corrs : Plot
        +clusters_means : DataFrame
        +clusters_PCA : Plot
        +clusters_tSNE : Plot
        +models : DataFrame
        +plot_clusters_ci : Plot
        +plot_models_errors : Plot
        +plot_models_rois : Plot
    }

    class clustering_functions {
        +clusterKmeans()
        +pareto_front()
        +.bootci()
    }

    class helper_functions {
        +errors_scores()
        +.min_max_norm()
        +.prepare_df()
    }

    robyn_clusters ..> ClusterResults : creates
    robyn_clusters --> clustering_functions : uses
    robyn_clusters --> helper_functions : uses
```

================
File: existing-code/inputs.R/README.md
================
### Flow chart

```mermaid
graph TD
    A[Start: robyn_inputs function] --> B[Check and process input parameters]
    B --> C{JSON file provided?}
    C -->|Yes| D[Import data from JSON]
    C -->|No| E[Process raw input data]

    E --> F[Check variable names]
    F --> G[Check for NA and negative values]
    G --> H[Process date variable]
    H --> I[Check dependent variable]
    I --> J[Process prophet variables]
    J --> K[Process context variables]
    K --> L[Process paid media variables]
    L --> M[Process organic variables]
    M --> N[Check factor variables]
    N --> O[Check all variables]
    O --> P[Check data dimensions]
    P --> Q[Set model window]
    Q --> R[Check adstock parameter]
    R --> S[Check hyperparameters]
    S --> T[Check calibration inputs]

    D --> U[Update InputCollect with JSON data]
    T --> U

    U --> V[Run robyn_engineering]
    V --> W[Return InputCollect]
    W --> X[End: Return processed inputs]

    subgraph "robyn_engineering function"
        V1[Transform prophet variables]
        V2[Apply adstock transformations]
        V3[Apply saturation transformations]
        V4[Prepare final input data]
    end

    V --> V1 --> V2 --> V3 --> V4
```

### Class Diagram

```mermaid
classDiagram
    class robyn_inputs {
        +dt_input
        +dt_holidays
        +date_var
        +dep_var
        +dep_var_type
        +prophet_vars
        +prophet_country
        +context_vars
        +paid_media_spends
        +paid_media_vars
        +organic_vars
        +factor_vars
        +window_start
        +window_end
        +adstock
        +hyperparameters
        +calibration_input
        +check_inputs()
        +robyn_engineering()
    }

    class InputCollect {
        +dt_input
        +dt_holidays
        +dt_mod
        +date_var
        +dayInterval
        +intervalType
        +dep_var
        +dep_var_type
        +prophet_vars
        +context_vars
        +paid_media_vars
        +paid_media_spends
        +organic_vars
        +all_media
        +all_ind_vars
        +factor_vars
        +window_start
        +window_end
        +adstock
        +hyperparameters
        +calibration_input
    }

    class check_inputs {
        +check_datevar()
        +check_depvar()
        +check_prophet()
        +check_context()
        +check_paidmedia()
        +check_organicvars()
        +check_factorvars()
        +check_allvars()
        +check_datadim()
        +check_windows()
        +check_adstock()
        +check_hyperparameters()
        +check_calibration()
    }

    class robyn_engineering {
        +feature_engineering()
        +adstock_transformations()
        +saturation_transformations()
    }

    robyn_inputs ..> InputCollect : creates
    robyn_inputs --> check_inputs : uses
    robyn_inputs --> robyn_engineering : uses
```

================
File: existing-code/model.R/README.md
================
### Flow chart

```mermaid
graph TD
    A[Start: robyn_run function] --> B[Process input parameters]
    B --> C[Initialize hyperparameters]
    C --> D[Set up parallel processing]
    D --> E[Run robyn_train]

    subgraph "robyn_train function"
        E1[Set up trials]
        E2[Run robyn_mmm for each trial]
        E3[Collect results]
    end

    E --> E1 --> E2 --> E3

    subgraph "robyn_mmm function"
        F1[Initialize model parameters]
        F2[Run nevergrad optimization]
        F3[Perform media transformations]
        F4[Fit ridge regression model]
        F5[Calculate model decomposition]
        F6[Collect results]
    end

    E2 --> F1 --> F2 --> F3 --> F4 --> F5 --> F6

    E3 --> G[Process final results]
    G --> H[Run robyn_outputs]
    H --> I[End: Return OutputModels]
```

### Class diagram

```mermaid
classDiagram
    class robyn_run {
        +InputCollect
        +hyperparameters
        +cores
        +iterations
        +trials
        +OutputModels
        +run()
    }

    class robyn_train {
        +InputCollect
        +hyperparameters
        +cores
        +iterations
        +trials
        +train()
    }

    class robyn_mmm {
        +InputCollect
        +hyperparameters
        +iterations
        +mmm()
    }

    class OutputModels {
        +resultHypParam
        +xDecompAgg
        +mediaVecCollect
        +xDecompVecCollect
    }

    robyn_run --> robyn_train : uses
    robyn_train --> robyn_mmm : uses
    robyn_run --> OutputModels : produces
```

================
File: existing-code/outputs.R/README.md
================
### Flowchart
```mermaid
graph TD
    A[Start: robyn_outputs function] --> B[Process input parameters]
    B --> C[Run robyn_pareto]
    C --> D[Process Pareto-optimal solutions]
    D --> E{Clustering enabled?}
    E -->|Yes| F[Run robyn_clusters]
    E -->|No| G[Skip clustering]
    F --> H[Generate output plots]
    G --> H
    H --> I[Export results to files]
    I --> J[Prepare OutputCollect structure]
    J --> K[End: Return OutputCollect]

    subgraph "robyn_pareto function"
        C1[Calculate Pareto fronts]
        C2[Select Pareto-optimal models]
        C3[Calculate model metrics]
    end
    C --> C1 --> C2 --> C3

    subgraph "Generate output plots"
        H1[Create Pareto front plot]
        H2[Create media share plot]
        H3[Create model performance plots]
    end
    H --> H1 --> H2 --> H3
```

### Class Diagram

```mermaid
classDiagram
    class robyn_outputs {
        +InputCollect
        +OutputModels
        +pareto_fronts
        +calibration_constraint
        +plot_folder
        +clusters
        +select_model
        +export
        +process_results()
        +run_pareto_analysis()
        +run_clustering()
        +generate_plots()
        +export_results()
    }

    class OutputCollect {
        +resultHypParam
        +xDecompAgg
        +mediaVecCollect
        +xDecompVecCollect
        +resultCalibration
        +allSolutions
        +allPareto
        +calibration_constraint
        +pareto_fronts
        +clusters
        +plot_folder
    }

    class robyn_pareto {
        +calculate_pareto_fronts()
        +select_pareto_models()
        +calculate_metrics()
    }

    class robyn_plots {
        +create_pareto_plot()
        +create_media_share_plot()
        +create_performance_plots()
    }

    robyn_outputs ..> OutputCollect : creates
    robyn_outputs --> robyn_pareto : uses
    robyn_outputs --> robyn_plots : uses
    robyn_outputs --> robyn_clusters : uses
```

================
File: existing-code/pareto.R/README.md
================
### Flowchart

```mermaid
graph TD
    A[Start: robyn_pareto function] --> B[Process input parameters]
    B --> C[Prepare data for Pareto analysis]
    C --> D[Calculate error metrics]
    D --> E[Apply calibration constraint]
    E --> F[Calculate Pareto fronts]
    F --> G[Select Pareto-optimal solutions]
    G --> H[Calculate model decomposition]
    H --> I[Prepare media vectors]
    I --> J[Generate Pareto plots]
    J --> K[Prepare output data]
    K --> L[End: Return Pareto results]

    subgraph "Pareto Front Calculation"
        F1[Sort solutions by errors]
        F2[Identify non-dominated solutions]
        F3[Assign Pareto front levels]
    end
    F --> F1 --> F2 --> F3
```

### Class Diagram

```mermaid
classDiagram
    class robyn_pareto {
        +InputCollect
        +OutputModels
        +pareto_fronts
        +calibration_constraint
        +calculate_pareto_fronts()
        +select_pareto_solutions()
        +calculate_decomposition()
        +prepare_output()
    }

    class ParetoResults {
        +pareto_solutions : list
        +pareto_fronts : int
        +resultHypParam : DataFrame
        +xDecompAgg : DataFrame
        +resultCalibration : DataFrame
        +mediaVecCollect : DataFrame
        +xDecompVecCollect : DataFrame
        +plotDataCollect : list
    }

    class pareto_functions {
        +pareto_front()
        +errors_scores()
    }

    class decomposition_functions {
        +model_decomp()
        +robyn_response()
    }

    robyn_pareto --> ParetoResults : produces
    robyn_pareto --> pareto_functions : uses
    robyn_pareto --> decomposition_functions : uses
```

================
File: existing-code/transformations.R/README.md
================
### Flowchart

```mermaid
graph TD
    A[Start: transform_adstock function] --> B{Adstock type?}
    B -->|Geometric| C[Apply geometric adstock]
    B -->|Weibull CDF| D[Apply Weibull CDF adstock]
    B -->|Weibull PDF| E[Apply Weibull PDF adstock]
    C --> F[Calculate inflation factor]
    D --> F
    E --> F
    F --> G[End: Return transformed values]

    H[Start: saturation_hill function] --> I[Calculate inflexion point]
    I --> J[Apply Hill function transformation]
    J --> K[End: Return saturated values]

    L[Start: robyn_engineering] --> M[Apply adstock transformations]
    M --> N[Apply saturation transformations]
    N --> O[Prepare final transformed data]
    O --> P[End: Return transformed data]
```

### Class Diagram

```mermaid
classDiagram
    class transform_adstock {
        +x : numeric vector
        +adstock : string
        +theta : numeric
        +shape : numeric
        +scale : numeric
        +windlen : integer
        +transform()
    }

    class adstock_geometric {
        +x : numeric vector
        +theta : numeric
        +apply()
    }

    class adstock_weibull {
        +x : numeric vector
        +shape : numeric
        +scale : numeric
        +windlen : integer
        +type : string
        +apply()
    }

    class saturation_hill {
        +x : numeric vector
        +alpha : numeric
        +gamma : numeric
        +x_marginal : numeric
        +apply()
    }

    class robyn_engineering {
        +InputCollect : list
        +hyperparameters : list
        +apply_transformations()
    }

    transform_adstock --> adstock_geometric : uses
    transform_adstock --> adstock_weibull : uses
    robyn_engineering --> transform_adstock : uses
    robyn_engineering --> saturation_hill : uses
```

================
File: overview/README.md
================
## Robyn MMM workflow

```mermaid
graph TD
    A[Start] --> B[Load Data]
    B --> C[robyn_inputs]
    C --> D[robyn_run]
    D --> E[robyn_outputs]
    E --> F[robyn_allocator]
    F --> G[End]

    subgraph "robyn_inputs"
        C1[Feature Engineering<br>Decompose time series]
        C2[Adstock Transformations<br>Apply adstock to media variables]
        C3[Saturation Transformations<br>Apply saturation to media variables]
        C4[check_inputs<br>Validate input data and parameters]
        C5[robyn_engineering<br>Prepare data for modeling]
    end

    subgraph "robyn_run"
        D1[Hyperparameter Optimization<br>Use Nevergrad to optimize hyperparameters]
        D2[Model Training<br>Train ridge regression model]
        D3[Model Evaluation<br>Calculate model performance metrics]
        D4[robyn_train<br>Manage model training process]
        D5[robyn_mmm<br>Core MMM function]
    end

    subgraph "robyn_outputs"
        E1[Pareto Front Analysis<br>Identify efficient model solutions]
        E2[Model Selection<br>Choose best model based on criteria]
        E3[robyn_pareto<br>Calculate Pareto-optimal solutions]
        E4[robyn_clusters<br>Cluster similar models]
    end

    subgraph "robyn_allocator"
        F1[Budget Allocation<br>Optimize budget across channels]
        F2[Response Curves<br>Generate media response curves]
        F3[robyn_response<br>Calculate channel-specific responses]
    end

    C --> C1 --> C2 --> C3
    C --> C4 --> C5
    D --> D1 --> D2 --> D3
    D --> D4 --> D5
    E --> E1 --> E2
    E --> E3 --> E4
    F --> F1 --> F2
    F --> F3

    subgraph "Inputs"
        H1[dt_input<br>Main input data]
        H2[dt_holidays<br>Holiday data]
        H3[paid_media_spends<br>Paid media spend data]
        H4[paid_media_vars<br>Paid media variables]
        H5[organic_vars<br>Organic media variables]
        H6[prophet_vars<br>Prophet decomposition variables]
        H7[hyperparameters<br>Model hyperparameters]
    end

    subgraph "Outputs"
        I1[InputCollect<br>Processed input data]
        I2[OutputModels<br>Trained model results]
        I3[OutputCollect<br>Aggregated model outputs]
        I4[AllocatorCollect<br>Budget allocation results]
    end

    H1 --> B
    H2 --> B
    H1 --> C
    H2 --> C
    H3 --> C
    H4 --> C
    H5 --> C
    H6 --> C
    H7 --> C
    C --> I1
    I1 --> D
    D --> I2
    I1 --> E
    I2 --> E
    E --> I3
    I1 --> F
    I3 --> F
    F --> I4

    subgraph "Auxiliary Functions"
        J1[checks.R<br>Input validation functions]
        J2[transformations.R<br>Adstock and saturation functions]
        J3[model.R<br>Core modeling functions]
        J4[pareto.R<br>Pareto optimization functions]
        J5[clusters.R<br>Model clustering functions]
        J6[plots.R<br>Plotting functions]
        J7[auxiliary.R<br>Helper functions]
        J8[json.R<br>JSON import/export functions]
    end

    J1 --> C4
    J2 --> C2
    J2 --> C3
    J3 --> D4
    J3 --> D5
    J4 --> E3
    J5 --> E4
    J6 --> E
    J6 --> F
    J7 --> C
    J7 --> D
    J7 --> E
    J7 --> F
    J8 --> C
    J8 --> D
    J8 --> E
    J8 --> F

    subgraph "External Libraries"
        K1[nevergrad<br>Hyperparameter optimization]
        K2[reticulate<br>Python integration]
        K3[prophet<br>Time series decomposition]
        K4[glmnet<br>Regularized regression]
    end

    K1 --> D1
    K2 --> D
    K3 --> C1
    K4 --> D2
```
