================================================================
Repopack Output File
================================================================

This file was generated by Repopack on: 2024-11-04T16:43:21.987Z

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This header section
2. Repository structure
3. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
1. This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
2. When processing this file, use the separators and "File:" markers to
  distinguish between different files in the repository.
3. Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repopack's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.



For more information about Repopack, visit: https://github.com/yamadashy/repopack

================================================================
Repository Structure
================================================================
allocator_visualizer.py
base_visualizer.py
cluster_visualization.py
feature_visualization.py
input_visualizer.py
model_convergence_visualizer.py
response_visualizer.py
robyn_visualizer.py
transformation_visualization.py

================================================================
Repository Files
================================================================

================
File: allocator_visualizer.py
================
from typing import Dict, List, Tuple, Optional
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from robyn.allocator.entities.allocation_results import AllocationResult


class AllocationPlotter:
    """Creates visualizations for allocation results matching R version."""

    def __init__(self, result: AllocationResult):
        """Initialize plotter with allocation results and default settings.

        Args:
            result: AllocationResult containing optimization results to visualize
        """
        # Store allocation results
        self.result = result

        # Use matplotlib's built-in clean style
        plt.style.use("bmh")

        # Set default plot settings
        plt.rcParams["figure.figsize"] = (12, 8)
        plt.rcParams["axes.grid"] = True
        plt.rcParams["axes.spines.top"] = False
        plt.rcParams["axes.spines.right"] = False

        # Store standard figure size and colors
        self.fig_size = (12, 8)
        self.colors = plt.cm.Set2(np.linspace(0, 1, 8))

        # Set color scheme
        self.current_color = "lightgray"
        self.optimal_color = "#4688C7"  # Steel blue
        self.positive_color = "#2ECC71"  # Green
        self.negative_color = "#E74C3C"  # Red

    def plot_all(self) -> Dict[str, plt.Figure]:
        """Generate all one-pager plots for allocation results.

        Returns:
            Dictionary of plot names to figures
        """
        return {
            "spend_allocation": self.plot_spend_allocation(),
            "response_curves": self.plot_response_curves(),
            "efficiency_frontier": self.plot_efficiency_frontier(),
            "spend_vs_response": self.plot_spend_vs_response(),
            "summary_metrics": self.plot_summary_metrics(),
        }

    def plot_spend_allocation(self) -> plt.Figure:
        """Plot spend allocation comparison between current and optimized."""
        if self.result is None:
            raise ValueError("No allocation results available. Call plot_all() first.")

        fig, ax = plt.subplots(figsize=self.fig_size)

        df = self.result.optimal_allocations
        channels = df["channel"].values
        x = np.arange(len(channels))
        width = 0.35

        # Plot bars
        current_spend = df["current_spend"].values
        optimal_spend = df["optimal_spend"].values

        ax.bar(
            x - width / 2, current_spend, width, label="Current", color=self.current_color, edgecolor="gray", alpha=0.7
        )
        ax.bar(
            x + width / 2,
            optimal_spend,
            width,
            label="Optimized",
            color=self.optimal_color,
            edgecolor="gray",
            alpha=0.7,
        )

        # Customize plot
        ax.set_xticks(x)
        ax.set_xticklabels(channels, rotation=45, ha="right")
        ax.set_ylabel("Spend")
        ax.set_title("Media Spend Allocation")
        ax.legend()

        # Add spend change percentage labels
        for i, (curr, opt) in enumerate(zip(current_spend, optimal_spend)):
            pct_change = ((opt / curr) - 1) * 100
            color = self.positive_color if pct_change >= 0 else self.negative_color
            ax.text(i, max(curr, opt), f"{pct_change:+.1f}%", ha="center", va="bottom", color=color)

        plt.tight_layout()
        return fig

    def plot_response_curves(self) -> plt.Figure:
        """Plot response curves with current and optimal points."""
        if self.result is None:
            raise ValueError("No allocation results available. Call plot_all() first.")

        curves_df = self.result.response_curves
        channels = curves_df["channel"].unique()
        n_channels = len(channels)
        ncols = min(3, n_channels)
        nrows = (n_channels + ncols - 1) // ncols

        fig, axes = plt.subplots(nrows, ncols, figsize=(15, 5 * nrows))
        if nrows == 1 and ncols == 1:
            axes = np.array([[axes]])
        elif nrows == 1 or ncols == 1:
            axes = axes.reshape(-1, 1)

        for idx, channel in enumerate(channels):
            row = idx // ncols
            col = idx % ncols
            ax = axes[row, col]

            channel_data = curves_df[curves_df["channel"] == channel]

            # Plot response curve
            ax.plot(channel_data["spend"], channel_data["response"], color=self.optimal_color, alpha=0.6)

            # Add current and optimal points
            current_data = channel_data[channel_data["is_current"]]
            optimal_data = channel_data[channel_data["is_optimal"]]

            if not current_data.empty:
                ax.scatter(
                    current_data["spend"].iloc[0],
                    current_data["response"].iloc[0],
                    color=self.negative_color,
                    label="Current",
                    s=100,
                )
            if not optimal_data.empty:
                ax.scatter(
                    optimal_data["spend"].iloc[0],
                    optimal_data["response"].iloc[0],
                    color=self.positive_color,
                    label="Optimal",
                    s=100,
                )

            ax.set_title(f"{channel} Response Curve")
            ax.legend()
            ax.grid(True, alpha=0.3)

        # Remove empty subplots
        for idx in range(n_channels, nrows * ncols):
            row = idx // ncols
            col = idx % ncols
            fig.delaxes(axes[row, col])

        plt.tight_layout()
        return fig

    def plot_efficiency_frontier(self) -> plt.Figure:
        """Plot efficiency frontier showing spend vs response relationship."""
        if self.result is None:
            raise ValueError("No allocation results available. Call plot_all() first.")

        fig, ax = plt.subplots(figsize=self.fig_size)

        df = self.result.optimal_allocations

        # Calculate totals
        current_total_spend = df["current_spend"].sum()
        current_total_response = df["current_response"].sum()
        optimal_total_spend = df["optimal_spend"].sum()
        optimal_total_response = df["optimal_response"].sum()

        # Plot points and line
        ax.scatter(
            current_total_spend, current_total_response, color=self.negative_color, s=100, label="Current", zorder=2
        )
        ax.scatter(
            optimal_total_spend, optimal_total_response, color=self.positive_color, s=100, label="Optimal", zorder=2
        )

        ax.plot(
            [current_total_spend, optimal_total_spend],
            [current_total_response, optimal_total_response],
            "--",
            color="gray",
            alpha=0.5,
            zorder=1,
        )

        # Add labels
        pct_spend_change = ((optimal_total_spend / current_total_spend) - 1) * 100
        pct_response_change = ((optimal_total_response / current_total_response) - 1) * 100

        ax.annotate(
            f"Spend: {pct_spend_change:+.1f}%\nResponse: {pct_response_change:+.1f}%",
            xy=(optimal_total_spend, optimal_total_response),
            xytext=(10, 10),
            textcoords="offset points",
            bbox=dict(facecolor="white", edgecolor="gray", alpha=0.7),
        )

        ax.set_xlabel("Total Spend")
        ax.set_ylabel("Total Response")
        ax.set_title("Efficiency Frontier")
        ax.legend()
        ax.grid(True, alpha=0.3)

        plt.tight_layout()
        return fig

    def plot_spend_vs_response(self) -> plt.Figure:
        """Plot channel-level spend vs response changes."""
        if self.result is None:
            raise ValueError("No allocation results available. Call plot_all() first.")

        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))

        df = self.result.optimal_allocations
        channels = df["channel"].values
        x = np.arange(len(channels))

        # Plot spend changes
        spend_pct = ((df["optimal_spend"] / df["current_spend"]) - 1) * 100
        colors = [self.negative_color if x < 0 else self.positive_color for x in spend_pct]
        ax1.bar(x, spend_pct, color=colors, alpha=0.7)
        ax1.set_xticks(x)
        ax1.set_xticklabels(channels, rotation=45, ha="right")
        ax1.set_ylabel("Spend Change %")
        ax1.axhline(y=0, color="black", linestyle="-", alpha=0.2)
        ax1.grid(True, alpha=0.3)

        # Add value labels
        for i, v in enumerate(spend_pct):
            ax1.text(i, v, f"{v:+.1f}%", ha="center", va="bottom" if v >= 0 else "top")

        # Plot response changes
        response_pct = ((df["optimal_response"] / df["current_response"]) - 1) * 100
        colors = [self.negative_color if x < 0 else self.positive_color for x in response_pct]
        ax2.bar(x, response_pct, color=colors, alpha=0.7)
        ax2.set_xticks(x)
        ax2.set_xticklabels(channels, rotation=45, ha="right")
        ax2.set_ylabel("Response Change %")
        ax2.axhline(y=0, color="black", linestyle="-", alpha=0.2)
        ax2.grid(True, alpha=0.3)

        # Add value labels
        for i, v in enumerate(response_pct):
            ax2.text(i, v, f"{v:+.1f}%", ha="center", va="bottom" if v >= 0 else "top")

        plt.tight_layout()
        return fig

    def plot_summary_metrics(self) -> plt.Figure:
        """Plot summary metrics including ROI/CPA changes."""
        if self.result is None:
            raise ValueError("No allocation results available. Call plot_all() first.")

        fig, ax = plt.subplots(figsize=self.fig_size)

        df = self.result.optimal_allocations
        channels = df["channel"].values

        # Calculate ROI or CPA metrics
        if self.result.metrics.get("dep_var_type") == "revenue":
            current_metric = df["current_response"] / df["current_spend"]
            optimal_metric = df["optimal_response"] / df["optimal_spend"]
            metric_name = "ROI"
        else:
            current_metric = df["current_spend"] / df["current_response"]
            optimal_metric = df["optimal_spend"] / df["optimal_response"]
            metric_name = "CPA"

        x = np.arange(len(channels))
        width = 0.35

        ax.bar(
            x - width / 2, current_metric, width, label=f"Current {metric_name}", color=self.current_color, alpha=0.7
        )
        ax.bar(
            x + width / 2, optimal_metric, width, label=f"Optimal {metric_name}", color=self.optimal_color, alpha=0.7
        )

        # Add value labels
        for i, (curr, opt) in enumerate(zip(current_metric, optimal_metric)):
            pct_change = ((opt / curr) - 1) * 100
            color = self.positive_color if pct_change >= 0 else self.negative_color
            ax.text(i, max(curr, opt), f"{pct_change:+.1f}%", ha="center", va="bottom", color=color)

        ax.set_xticks(x)
        ax.set_xticklabels(channels, rotation=45, ha="right")
        ax.set_ylabel(metric_name)
        ax.set_title(f"Channel {metric_name} Comparison")
        ax.legend()
        ax.grid(True, alpha=0.3)

        plt.tight_layout()
        return fig

    def save_plots(self, plots: Dict[str, plt.Figure], directory: str) -> None:
        """Save all plots to specified directory."""
        for name, fig in plots.items():
            fig.savefig(f"{directory}/allocation_{name}.png", dpi=300, bbox_inches="tight")
            plt.close(fig)

================
File: base_visualizer.py
================
import matplotlib.pyplot as plt


class BaseVisualizer:
    def __init__(self):
        pass

    def _setup_plot(self):
        # Common plot setup logic
        pass

================
File: cluster_visualization.py
================
# pyre-strict
from typing import Dict
from robyn.modeling.entities.clustering_results import ClusteredResult
from robyn.modeling.clustering.clustering_config import ClusteringConfig


class ClusterVisualizer:
    """
    Class for visualizing clustering results.
    """

    def __init__(self, results: ClusteredResult):
        """
        Initialize the ClusterVisualizer with clustering results.

        Args:
            results (ClusteredResult): Results of the clustering process.
        """
        self.results = results

    def plot_wss(self) -> None:
        """
        Plot the Within-Cluster Sum of Squares (WSS) for different numbers of clusters.
        """
        pass

    def plot_correlations(self) -> None:
        """
        Plot the correlations between variables for each cluster.
        """
        pass

    def plot_cluster_means(self) -> None:
        """
        Plot the mean values of variables for each cluster.
        """
        pass

    def plot_dimensionality_reduction(self) -> None:
        """
        Plot the results of dimensionality reduction (PCA or t-SNE).
        """
        pass

    def plot_confidence_intervals(
        self, confidence_data: Dict[str, float], config: ClusteringConfig
    ) -> None:
        """
        Creates a plot of the bootstrapped confidence intervals for model performance metrics.

        Args:
            confidence_data (Dict[str, float]): The data containing confidence intervals for plotting.
            config (ClusteringConfig): Configuration for the clustering process.

        Returns:
            None
        """
        pass

    def plot_top_solutions(self, config: ClusteringConfig) -> None:
        """
        Creates plots for the top solutions based on their performance metrics.

        Args:
            config (ClusteringConfig): Configuration for the clustering process.

        Returns:
            None
        """
        pass

================
File: feature_visualization.py
================
from typing import List, Dict, Any, Optional
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from robyn.data.entities.mmmdata import MMMData
from robyn.data.entities.hyperparameters import Hyperparameters, ChannelHyperparameters
from robyn.modeling.feature_engineering import FeaturizedMMMData  # New import


class FeaturePlotter:
    """
    A class for creating various plots related to feature engineering in the Robyn framework.
    """

    def __init__(self, mmm_data: MMMData, hyperparameters: Hyperparameters):
        """
        Initialize the FeaturePlotter class.

        Args:
            mmm_data (MMMData): The input data and specifications for the MMM.
            hyperparameters (Hyperparameters): The hyperparameters for the model.
        """
        self.mmm_data = mmm_data
        self.hyperparameters = hyperparameters

    def plot_adstock(self, channel: str) -> plt.Figure:
        """
        Plot the adstock transformation for a specific channel.

        Args:
            channel (str): The name of the channel to plot adstock for.

        Returns:
            plt.Figure: A matplotlib Figure object containing the adstock plot.
        """
        pass

    def plot_saturation(self, channel: str) -> plt.Figure:
        """
        Plot the saturation curve transformation for a specific channel.

        Args:
            channel (str): The name of the channel to plot saturation for.

        Returns:
            plt.Figure: A matplotlib Figure object containing the saturation curves plot.
        """
        pass

    def plot_spend_exposure(self, featurized_data: FeaturizedMMMData, channel: str) -> plt.Figure:
        """
        Plot the relationship between spend and exposure for a given channel.

        Args:
            featurized_data (FeaturizedMMMData): The featurized data after feature engineering.
            channel (str): The name of the channel being plotted.

        Returns:
            plt.Figure: A matplotlib Figure object containing the spend-exposure plot.
        """
        if channel not in featurized_data.modNLS["results"]:
            raise ValueError(f"No spend-exposure data available for channel: {channel}")

        res = featurized_data.modNLS["results"][channel]
        plot_data = featurized_data.modNLS["plots"][channel]

        fig, ax = plt.subplots(figsize=(10, 6))

        # Plot scatter of actual data
        sns.scatterplot(x="spend", y="exposure", data=plot_data, ax=ax, alpha=0.6, label="Actual")

        # Plot fitted line
        sns.lineplot(x="spend", y="yhat", data=plot_data, ax=ax, color="red", label="Fitted")

        ax.set_xlabel(f"Spend [{channel}]")
        ax.set_ylabel(f"Exposure [{channel}]")
        ax.set_title(f"Spend vs Exposure for {channel}")

        # Add model information to the plot
        model_type = res["model_type"]
        rsq = res["rsq"]
        if model_type == "nls":
            Vmax, Km = res["coef"]["Vmax"], res["coef"]["Km"]
            ax.text(
                0.05,
                0.95,
                f"Model: Michaelis-Menten\nR² = {rsq:.4f}\nVmax = {Vmax:.2f}\nKm = {Km:.2f}",
                transform=ax.transAxes,
                verticalalignment="top",
                bbox=dict(boxstyle="round", facecolor="white", alpha=0.7),
            )
        else:
            coef = res["coef"]["coef"]
            ax.text(
                0.05,
                0.95,
                f"Model: Linear\nR² = {rsq:.4f}\nCoefficient = {coef:.4f}",
                transform=ax.transAxes,
                verticalalignment="top",
                bbox=dict(boxstyle="round", facecolor="white", alpha=0.7),
            )

        plt.legend()
        plt.tight_layout()

        return fig

    def plot_feature_importance(self, feature_importance: Dict[str, float]) -> plt.Figure:
        """
        Plot the importance of different features in the model.

        Args:
            feature_importance (Dict[str, float]): Dictionary of feature importances.

        Returns:
            plt.Figure: A matplotlib Figure object containing the feature importance plot.
        """
        pass

    def plot_response_curves(self, featurized_data: FeaturizedMMMData) -> Dict[str, plt.Figure]:
        """
        Plot response curves for different channels.

        Args:
            featurized_data (FeaturizedMMMData): The featurized data after feature engineering.

        Returns:
            Dict[str, plt.Figure]: Dictionary mapping channel names to their respective response curve plots.
        """
        dt_mod = featurized_data.dt_mod
        # Rest of the method implementation
        pass

================
File: input_visualizer.py
================
from typing import Dict, Any
import matplotlib.pyplot as plt
from .base_visualizer import BaseVisualizer

class InputVisualizer(BaseVisualizer):
    def __init__(self, input_data: Dict[str, Any]):
        super().__init__()
        self.input_data = input_data

    def plot_adstock(self) -> plt.Figure:
        """
        Create example plots for adstock hyperparameters.

        Returns:
            plt.Figure: The generated figure.
        """
        fig, ax = plt.subplots()
        # Add plotting logic here
        return fig

    def plot_saturation(self) -> plt.Figure:
        """
        Create example plots for saturation hyperparameters.

        Returns:
            plt.Figure: The generated figure.
        """
        fig, ax = plt.subplots()
        # Add plotting logic here
        return fig

    def plot_spend_exposure_fit(self) -> Dict[str, plt.Figure]:
        """
        Check spend exposure fit if available.

        Returns:
            Dict[str, plt.Figure]: A dictionary of generated figures.
        """
        figures = {}
        # Add plotting logic here
        return figures

================
File: model_convergence_visualizer.py
================
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from typing import List
import io
import base64
from robyn.modeling.entities.modeloutputs import Trial


class ModelConvergenceVisualizer:
    def __init__(self, n_cuts: int, nrmse_win: List[float]):
        self.n_cuts = n_cuts
        self.nrmse_win = nrmse_win

    def create_moo_distrb_plot(self, dt_objfunc_cvg: pd.DataFrame, conv_msg: List[str]) -> str:
        dt_objfunc_cvg["id"] = dt_objfunc_cvg["cuts"].astype(int)
        dt_objfunc_cvg["cuts"] = pd.Categorical(
            dt_objfunc_cvg["cuts"], categories=sorted(dt_objfunc_cvg["cuts"].unique(), reverse=True)
        )

        for error_type in dt_objfunc_cvg["error_type"].unique():
            mask = dt_objfunc_cvg["error_type"] == error_type
            dt_objfunc_cvg.loc[mask, "value"] = np.clip(
                dt_objfunc_cvg.loc[mask, "value"], *np.quantile(dt_objfunc_cvg.loc[mask, "value"], self.nrmse_win)
            )

        fig, ax = plt.subplots(figsize=(12, 8))
        sns.violinplot(data=dt_objfunc_cvg, x="value", y="cuts", hue="error_type", split=True, inner="quartile", ax=ax)
        ax.set_xlabel("Objective functions")
        ax.set_ylabel("Iterations [#]")
        ax.set_title("Objective convergence by iterations quantiles")
        plt.tight_layout()

        # Add convergence messages as caption
        plt.figtext(0.5, 0.01, "\n".join(conv_msg), ha="center", fontsize=8, wrap=True)

        return self._convert_plot_to_base64(fig)

    def create_moo_cloud_plot(self, df: pd.DataFrame, conv_msg: List[str], calibrated: bool) -> str:
        df["nrmse"] = np.clip(df["nrmse"], *np.quantile(df["nrmse"], self.nrmse_win))

        fig, ax = plt.subplots(figsize=(10, 8))
        scatter = ax.scatter(df["nrmse"], df["decomp.rssd"], c=df["ElapsedAccum"], cmap="viridis")

        if calibrated and "mape" in df.columns:
            sizes = (df["mape"] - df["mape"].min()) / (df["mape"].max() - df["mape"].min())
            sizes = sizes * 100 + 10  # Scale sizes
            ax.scatter(df["nrmse"], df["decomp.rssd"], s=sizes, alpha=0.5)

        plt.colorbar(scatter, label="Time [s]")
        ax.set_xlabel("NRMSE")
        ax.set_ylabel("DECOMP.RSSD")
        ax.set_title("Multi-objective evolutionary performance")

        # Add convergence messages as caption
        plt.figtext(0.5, 0.01, "\n".join(conv_msg), ha="center", fontsize=8, wrap=True)

        plt.tight_layout()

        return self._convert_plot_to_base64(fig)

    @staticmethod
    def _convert_plot_to_base64(fig: plt.Figure) -> str:
        buffer = io.BytesIO()
        fig.savefig(buffer, format="png")
        buffer.seek(0)
        image_png = buffer.getvalue()
        buffer.close()
        graphic = base64.b64encode(image_png)
        return graphic.decode("utf-8")

    def create_ts_validation_plot(self, trials: List[Trial]) -> str:
        result_hyp_param = pd.concat([trial.result_hyp_param for trial in trials], ignore_index=True)
        result_hyp_param["trial"] = result_hyp_param.groupby("solID").cumcount() + 1
        result_hyp_param["iteration"] = result_hyp_param.index + 1  # Use this instead of 'i'

        result_hyp_param_long = result_hyp_param.melt(
            id_vars=["solID", "trial", "train_size", "iteration"],
            value_vars=["rsq_train", "rsq_val", "rsq_test", "nrmse_train", "nrmse_val", "nrmse_test"],
            var_name="metric",
            value_name="value",
        )

        result_hyp_param_long["dataset"] = result_hyp_param_long["metric"].str.split("_").str[-1]
        result_hyp_param_long["metric_type"] = result_hyp_param_long["metric"].str.split("_").str[0]

        # Winsorize the data
        result_hyp_param_long["value"] = result_hyp_param_long.groupby("metric_type")["value"].transform(
            lambda x: np.clip(x, np.percentile(x, self.nrmse_win[0] * 100), np.percentile(x, self.nrmse_win[1] * 100))
        )

        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10), height_ratios=[3, 1])

        # NRMSE plot
        sns.scatterplot(
            data=result_hyp_param_long[result_hyp_param_long["metric_type"] == "nrmse"],
            x="iteration",
            y="value",
            hue="dataset",
            style="trial",
            alpha=0.5,
            ax=ax1,
        )
        sns.lineplot(
            data=result_hyp_param_long[result_hyp_param_long["metric_type"] == "nrmse"],
            x="iteration",
            y="value",
            hue="dataset",
            ax=ax1,
        )
        ax1.set_ylabel("NRMSE [Winsorized]")
        ax1.set_xlabel("Iteration")
        ax1.legend(title="Dataset")

        # Train Size plot
        sns.scatterplot(data=result_hyp_param, x="iteration", y="train_size", hue="trial", ax=ax2, legend=False)
        ax2.set_ylabel("Train Size")
        ax2.set_xlabel("Iteration")
        ax2.set_ylim(0, 1)
        ax2.yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: "{:.0%}".format(y)))

        plt.suptitle("Time-series validation & Convergence")
        plt.tight_layout()

        return self._convert_plot_to_base64(fig)

    def _convert_plot_to_base64(self, fig: plt.Figure) -> str:
        buffer = io.BytesIO()
        fig.savefig(buffer, format="png")
        buffer.seek(0)
        image_png = buffer.getvalue()
        buffer.close()
        graphic = base64.b64encode(image_png)
        return graphic.decode("utf-8")

================
File: response_visualizer.py
================
from typing import Dict, Any
import matplotlib.pyplot as plt
from .base_visualizer import BaseVisualizer

class ResponseVisualizer(BaseVisualizer):
    def __init__(self, response_data: Dict[str, Any]):
        super().__init__()
        self.response_data = response_data

    def plot_response(self) -> plt.Figure:
        """
        Plot response curves.

        Returns:
            plt.Figure: The generated figure.
        """
        pass

    def plot_marginal_response(self) -> plt.Figure:
        """
        Plot marginal response curves.

        Returns:
            plt.Figure: The generated figure.
        """
        pass

================
File: robyn_visualizer.py
================
from typing import Dict, Any
import matplotlib.pyplot as plt
from .input_visualizer import InputVisualizer
from .model_visualizer import ModelVisualizer
from .allocator_visualizer import AllocatorVisualizer
from .response_visualizer import ResponseVisualizer

class RobynVisualizer:
    def __init__(self):
        self.input_visualizer = None
        self.model_visualizer = None
        self.allocator_visualizer = None
        self.response_visualizer = None

    def set_input_data(self, input_data: Dict[str, Any]):
        self.input_visualizer = InputVisualizer(input_data)

    def set_model_data(self, model_data: Dict[str, Any]):
        self.model_visualizer = ModelVisualizer(model_data)

    def set_allocator_data(self, allocator_data: Dict[str, Any]):
        self.allocator_visualizer = AllocatorVisualizer(allocator_data)

    def set_response_data(self, response_data: Dict[str, Any]):
        self.response_visualizer = ResponseVisualizer(response_data)

    def plot_adstock(self) -> plt.Figure:
        return self.input_visualizer.plot_adstock()

    def plot_saturation(self) -> plt.Figure:
        return self.input_visualizer.plot_saturation()

    def plot_moo_distribution(self) -> plt.Figure:
        return self.model_visualizer.plot_moo_distribution()

    def plot_moo_cloud(self) -> plt.Figure:
        return self.model_visualizer.plot_moo_cloud()

    def plot_ts_validation(self) -> plt.Figure:
        return self.model_visualizer.plot_ts_validation()

    def plot_onepager(self, input_collect: Dict[str, Any], output_collect: Dict[str, Any], select_model: str) -> Dict[str, plt.Figure]:
        return self.model_visualizer.plot_onepager(input_collect, output_collect, select_model)

    def plot_allocator(self) -> plt.Figure:
        return self.allocator_visualizer.plot_allocator()

    def plot_response(self) -> plt.Figure:
        return self.response_visualizer.plot_response()

    def plot_marginal_response(self) -> plt.Figure:
        return self.response_visualizer.plot_marginal_response()

================
File: transformation_visualization.py
================
# pyre-strict

import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import numpy as np
from typing import List, Tuple, Optional


class TransformationVisualizer:
    def __init__(self):
        self.adstock_figures: Optional[Tuple[plt.Figure, plt.Figure]] = None
        self.saturation_figures: Optional[Tuple[plt.Figure, plt.Figure]] = None

    def create_adstock_plots(self) -> None:
        """
        Generate adstock visualization plots and store them as instance variables.
        """
        pass

    def create_saturation_plots(self) -> None:
        """
        Generate saturation visualization plots and store them as instance variables.
        """
        pass

    def get_adstock_plots(self) -> Optional[Tuple[plt.Figure, plt.Figure]]:
        """
        Retrieve the adstock plots.

        Returns:
            Optional[Tuple[plt.Figure, plt.Figure]]: Tuple of matplotlib figures for adstock plots
        """
        pass

    def get_saturation_plots(self) -> Optional[Tuple[plt.Figure, plt.Figure]]:
        """
        Retrieve the saturation plots.

        Returns:
            Optional[Tuple[plt.Figure, plt.Figure]]: Tuple of matplotlib figures for saturation plots
        """
        pass

    def display_adstock_plots(self) -> None:
        """
        Display the adstock plots.
        """
        pass

    def display_saturation_plots(self) -> None:
        """
        Display the saturation plots.
        """
        pass

    def save_adstock_plots(self, filenames: List[str]) -> None:
        """
        Save the adstock plots to files.

        Args:
            filenames (List[str]): List of filenames to save the plots
        """
        pass

    def save_saturation_plots(self, filenames: List[str]) -> None:
        """
        Save the saturation plots to files.

        Args:
            filenames (List[str]): List of filenames to save the plots
        """
        pass
