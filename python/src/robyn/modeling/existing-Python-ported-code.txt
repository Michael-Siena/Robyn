================================================================
Repopack Output File
================================================================

This file was generated by Repopack on: 2024-08-30T03:32:39.705Z

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This header section
2. Repository structure
3. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
1. This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
2. When processing this file, use the separators and "File:" markers to
  distinguish between different files in the repository.
3. Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repopack's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.



For more information about Repopack, visit: https://github.com/yamadashy/repopack

================================================================
Repository Structure
================================================================
documentations/
  classdiagram/
    README.md
  flowchart/
    README.md
entities/
  calibration_result.py
  convergence_result.py
  mmmdata_collection.py
  model_refresh_config.py
  modeloutput_collection.py
  modeloutput.py
  modelrun_trials_config.py
calibration.py
convergence.py
feature_engineering.py
mmm_model_executor.py
mmm_pareto_optimizer.py
model_clusters_analyzer.py
model_evaluation.py
model_refresh.py
model_response.py

================================================================
Repository Files
================================================================

================
File: documentations/classdiagram/README.md
================
```mermaid
classDiagram
    class MMMDataCollection {
        +dt_input: DataFrame
        +dt_holidays: DataFrame
        +mmmdata_spec: MMMDataSpec
        +data: DataFrame
    }

    class ModelOutputCollection {
        +resultHypParam: ResultHypParam
        +xDecompAgg: XDecompAgg
        +mediaVecCollect: DataFrame
        +xDecompVecCollect: DataFrame
        +resultCalibration: DataFrame
        +model_output: ModelOutput
        +allSolutions: List[str]
        +allPareto: Dict
        +calibration_constraint: float
        +pareto_fronts: int
        +selectID: str
        +cores: int
        +iterations: int
        +trials: List
        +intercept_sign: str
        +nevergrad_algo: str
        +add_penalty_factor: bool
        +seed: int
        +hyper_fixed: bool
        +hyper_updated: Dict
        +update(kwargs)
    }

    class ModelOutput {
        +trials: List[Trial]
        +metadata: Metadata
        +seed: int
        +create(model_output_dict: Dict) ModelOutput
    }

    class FeatureEngineering {
        -mmm_data_collection: MMMDataCollection
        +feature_engineering(quiet: bool) MMMDataCollection
        -__prepare_data() DataFrame
        -__create_rolling_window_data(dt_transform: DataFrame) DataFrame
        -__calculate_media_cost_factor(dt_input_roll_wind: DataFrame) List[float]
        -__fit_spend_exposure(dt_spend_mod_input: DataFrame, media_cost_factor: float, media_var: str) Dict
        -__run_models(dt_input_roll_wind: DataFrame, media_cost_factor: List[float]) Tuple
    }

    class MMMModelExecutor {
        +model_run(mmmdata_collection: MMMDataCollection, ...)
        +print_robyn_models(x: Any)
        +model_train(resultHyper, hyper_collect: Dict, ...)
        +run_nevergrad_optimization(mmmdata_collection: MMMDataCollection, ...)
        -model_fit_iteration(iteration: int, ...) ModelOutputTrialResult
        +model_decomp(coefs: Any, y_pred: Any, ...)
        +model_refit(x_train: Any, y_train: Any, ...)
        -__get_rsq(true: Any, predicted: Any, ...) float
        -__lambda_seq(x: Any, y: Any, ...) Any
        -__hyper_collector(InputCollect: Dict, ...)
        -__init_msgs_run(InputCollect: Dict, ...)
    }

    class ParetoOptimizer {
        +pareto_optimize(mmmdata_collection: MMMDataCollection, modeloutput: ModelOutput, ...) Dict
        +pareto_front(x: np.ndarray, y: np.ndarray, ...) DataFrame
        +get_pareto_fronts(pareto_fronts: Union[str, int]) int
        +run_dt_resp(respN: int, mmmdata_collection: MMMDataCollection, ...) DataFrame
    }

    class ModelClustersAnalyzer {
        +model_clusters_analyze(input: Dict, dep_var_type: str, ...) Dict
        -_determine_optimal_k(df: DataFrame, max_clusters: int, ...) int
        -_clusterKmeans_auto(df: DataFrame, ...) Tuple
        -_plot_wss_and_save(wss: List[float], path: str, ...)
        -_prepare_df(x: DataFrame, all_media: List[str], ...) DataFrame
        -_clusters_df(df: DataFrame, all_paid: List[str], ...) DataFrame
        -_confidence_calcs(xDecompAgg: DataFrame, df: DataFrame, ...) Dict
        -_plot_clusters_ci(sim_collect: DataFrame, df_ci: DataFrame, ...) Any
    }

    class ModelRefresh {
        +model_refresh(mmmdata_collection: MMMDataCollection, model_output_collection: ModelOutputCollection, ...) Any
        +model_refresh_from_robyn_object(robyn_object: Dict, refresh_config: ModelRefreshConfig, ...) Any
        +model_refresh_from_reloadedstate(json_file: str, refresh_config: ModelRefreshConfig, ...) Any
    }

    class ModelResponse {
        +robyn_response(InputCollect, OutputCollect, ...)
        +robyn_response_from_robyn_object(robyn_object, ...)
        +robyn_response_from_json(json_file, ...)
    }

    MMMDataCollection -- ModelOutputCollection
    ModelOutputCollection -- ModelOutput
    FeatureEngineering -- MMMDataCollection
    MMMModelExecutor -- MMMDataCollection
    MMMModelExecutor -- ModelOutputCollection
    ParetoOptimizer -- MMMDataCollection
    ParetoOptimizer -- ModelOutput
    ModelClustersAnalyzer -- ModelOutputCollection
    ModelRefresh -- MMMDataCollection
    ModelRefresh -- ModelOutputCollection
    ModelResponse -- MMMDataCollection
    ModelResponse -- ModelOutputCollection

================
File: documentations/flowchart/README.md
================
```mermaid
graph TD
    A[Start] --> B[Load Data]
    B --> C[robyn_inputs]
    C --> D[robyn_run]
    D --> E[robyn_outputs]
    E --> F[robyn_allocator]
    F --> G[End]

    subgraph "robyn_inputs"
        C1[Feature Engineering<br>Decompose time series]
        C2[Adstock Transformations<br>Apply adstock to media variables]
        C3[Saturation Transformations<br>Apply saturation to media variables]
        C4[check_inputs<br>Validate input data and parameters]
        C5[robyn_engineering<br>Prepare data for modeling]
    end

    subgraph "robyn_run"
        D1[Hyperparameter Optimization<br>Use Nevergrad to optimize hyperparameters]
        D2[Model Training<br>Train ridge regression model]
        D3[Model Evaluation<br>Calculate model performance metrics]
        D4[robyn_train<br>Manage model training process]
        D5[robyn_mmm<br>Core MMM function]
    end

    subgraph "robyn_outputs"
        E1[Pareto Front Analysis<br>Identify efficient model solutions]
        E2[Model Selection<br>Choose best model based on criteria]
        E3[robyn_pareto<br>Calculate Pareto-optimal solutions]
        E4[robyn_clusters<br>Cluster similar models]
    end

    subgraph "robyn_allocator"
        F1[Budget Allocation<br>Optimize budget across channels]
        F2[Response Curves<br>Generate media response curves]
        F3[robyn_response<br>Calculate channel-specific responses]
    end

    C --> C1 --> C2 --> C3
    C --> C4 --> C5
    D --> D1 --> D2 --> D3
    D --> D4 --> D5
    E --> E1 --> E2
    E --> E3 --> E4
    F --> F1 --> F2
    F --> F3

    subgraph "Inputs"
        H1[dt_input<br>Main input data]
        H2[dt_holidays<br>Holiday data]
        H3[paid_media_spends<br>Paid media spend data]
        H4[paid_media_vars<br>Paid media variables]
        H5[organic_vars<br>Organic media variables]
        H6[prophet_vars<br>Prophet decomposition variables]
        H7[hyperparameters<br>Model hyperparameters]
    end

    subgraph "Outputs"
        I1[InputCollect<br>Processed input data]
        I2[OutputModels<br>Trained model results]
        I3[OutputCollect<br>Aggregated model outputs]
        I4[AllocatorCollect<br>Budget allocation results]
    end

    H1 --> B
    H2 --> B
    H1 --> C
    H2 --> C
    H3 --> C
    H4 --> C
    H5 --> C
    H6 --> C
    H7 --> C
    C --> I1
    I1 --> D
    D --> I2
    I1 --> E
    I2 --> E
    E --> I3
    I1 --> F
    I3 --> F
    F --> I4

    subgraph "Auxiliary Functions"
        J1[checks.R<br>Input validation functions]
        J2[transformations.R<br>Adstock and saturation functions]
        J3[model.R<br>Core modeling functions]
        J4[pareto.R<br>Pareto optimization functions]
        J5[clusters.R<br>Model clustering functions]
        J6[plots.R<br>Plotting functions]
        J7[auxiliary.R<br>Helper functions]
        J8[json.R<br>JSON import/export functions]
    end

    J1 --> C4
    J2 --> C2
    J2 --> C3
    J3 --> D4
    J3 --> D5
    J4 --> E3
    J5 --> E4
    J6 --> E
    J6 --> F
    J7 --> C
    J7 --> D
    J7 --> E
    J7 --> F
    J8 --> C
    J8 --> D
    J8 --> E
    J8 --> F

    subgraph "External Libraries"
        K1[nevergrad<br>Hyperparameter optimization]
        K2[reticulate<br>Python integration]
        K3[prophet<br>Time series decomposition]
        K4[glmnet<br>Regularized regression]
    end

    K1 --> D1
    K2 --> D
    K3 --> C1
    K4 --> D2

================
File: entities/calibration_result.py
================
# pyre-strict

from dataclasses import dataclass
from typing import List
from datetime import date
import pandas as pd

@dataclass(frozen=True)
class CalibrationResult:
    """Dataclass to represent calibration results"""
    lift_media: List[str]  # Renamed to follow PEP8 naming conventions
    lift_start: List[date]
    lift_end: List[date]
    lift_abs: List[float]
    decomp_start: List[date]
    decomp_end: List[date]
    decomp_abs_scaled: List[float]
    decomp_abs_total_scaled: List[float]
    calibrated_pct: List[float]
    mape_lift: List[float]

    @classmethod
    def from_dataframe(cls, df: pd.DataFrame) -> 'CalibrationResult':
        """Create CalibrationResult from a pandas DataFrame"""
        return cls(
            lift_media=df['liftMedia'].tolist(),
            lift_start=df['liftStart'].tolist(),
            lift_end=df['liftEnd'].tolist(),
            lift_abs=df['liftAbs'].tolist(),
            decomp_start=df['decompStart'].tolist(),
            decomp_end=df['decompEnd'].tolist(),
            decomp_abs_scaled=df['decompAbsScaled'].tolist(),
            decomp_abs_total_scaled=df['decompAbsTotalScaled'].tolist(),
            calibrated_pct=df['calibrated_pct'].tolist(),
            mape_lift=df['mape_lift'].tolist()
        )

    def to_dataframe(self) -> pd.DataFrame:
        """Convert CalibrationResult to a pandas DataFrame"""
        return pd.DataFrame({
            'liftMedia': self.lift_media,
            'liftStart': self.lift_start,
            'liftEnd': self.lift_end,
            'liftAbs': self.lift_abs,
            'decompStart': self.decomp_start,
            'decompEnd': self.decomp_end,
            'decompAbsScaled': self.decomp_abs_scaled,
            'decompAbsTotalScaled': self.decomp_abs_total_scaled,
            'calibrated_pct': self.calibrated_pct,
            'mape_lift': self.mape_lift
        })

    def __post_init__(self) -> None:
        """Validate that all lists have the same length"""
        list_lengths = [len(getattr(self, attr)) for attr in self.__dataclass_fields__]
        if len(set(list_lengths)) > 1:
            raise ValueError("All lists in CalibrationResult must have the same length")

================
File: entities/convergence_result.py
================
# pyre-strict

from typing import TypedDict, Any
import matplotlib.pyplot as plt

class ConvergenceResult(TypedDict):
    """
    ConvergenceResult is a typed dictionary that stores the results of the convergence analysis.

    Attributes:
        moo_distrb_plot (plt.Figure): The distribution plot for the multi-objective optimization.
        moo_cloud_plot (plt.Figure): The cloud plot for the multi-objective optimization.
        errors (Any): Errors encountered during the convergence analysis.
        conv_msg (str): Convergence message.
        sd_qtref (float): Standard deviation quantile reference.
        med_lowb (float): Median lower bound.
    """
    moo_distrb_plot: plt.Figure
    moo_cloud_plot: plt.Figure
    errors: Any
    conv_msg: str
    sd_qtref: float
    med_lowb: float

================
File: entities/mmmdata_collection.py
================
# mmmdata_collection.py

from datetime import datetime
from typing import Any, Dict, List, Optional

import numpy as np
import pandas as pd


class MMMDataCollection:
    def __init__(self):
        self.dt_input: pd.DataFrame = pd.DataFrame()
        self.dt_holidays: pd.DataFrame = pd.DataFrame()
        self.dt_mod: pd.DataFrame = pd.DataFrame()
        self.dt_modRollWind: pd.DataFrame = pd.DataFrame()
        self.xDecompAggPrev: Optional[pd.DataFrame] = None
        self.date_var: str = ""
        self.dayInterval: int = 1
        self.intervalType: str = "day"
        self.dep_var: str = ""
        self.dep_var_type: str = ""
        self.prophet_vars: List[str] = []
        self.prophet_signs: List[str] = []
        self.prophet_country: Optional[str] = None
        self.context_vars: List[str] = []
        self.context_signs: List[str] = []
        self.paid_media_vars: List[str] = []
        self.paid_media_signs: List[str] = []
        self.paid_media_spends: List[str] = []
        self.paid_media_total: float = 0.0
        self.exposure_vars: List[str] = []
        self.organic_vars: List[str] = []
        self.organic_signs: List[str] = []
        self.all_media: List[str] = []
        self.all_ind_vars: List[str] = []
        self.factor_vars: List[str] = []
        self.unused_vars: List[str] = []
        self.window_start: datetime = datetime.now()
        self.rollingWindowStartWhich: int = 0
        self.window_end: datetime = datetime.now()
        self.rollingWindowEndWhich: int = 0
        self.rollingWindowLength: int = 0
        self.totalObservations: int = 0
        self.refreshAddedStart: datetime = datetime.now()
        self.adstock: str = "geometric"
        self.hyperparameters: Dict[str, Any] = {}
        self.calibration_input: Optional[pd.DataFrame] = None
        self.custom_params: Dict[str, Any] = {}

    def set_input_data(self, dt_input: pd.DataFrame) -> None:
        """Set the input data for the MMM."""
        self.dt_input = dt_input
        self.totalObservations = len(dt_input)

    def set_holidays_data(self, dt_holidays: pd.DataFrame) -> None:
        """Set the holidays data for the MMM."""
        self.dt_holidays = dt_holidays

    def set_date_variable(self, date_var: str) -> None:
        """Set the date variable name and calculate interval information."""
        self.date_var = date_var
        self._calculate_interval_info()

    def set_dependent_variable(self, dep_var: str, dep_var_type: str) -> None:
        """Set the dependent variable name and type."""
        self.dep_var = dep_var
        self.dep_var_type = dep_var_type

    def set_prophet_variables(
        self,
        prophet_vars: List[str],
        prophet_signs: List[str],
        prophet_country: Optional[str],
    ) -> None:
        """Set the Prophet-related variables."""
        self.prophet_vars = prophet_vars
        self.prophet_signs = prophet_signs
        self.prophet_country = prophet_country

    def set_context_variables(
        self, context_vars: List[str], context_signs: List[str]
    ) -> None:
        """Set the context variables."""
        self.context_vars = context_vars
        self.context_signs = context_signs

    def set_paid_media_variables(
        self,
        paid_media_vars: List[str],
        paid_media_signs: List[str],
        paid_media_spends: List[str],
    ) -> None:
        """Set the paid media variables."""
        self.paid_media_vars = paid_media_vars
        self.paid_media_signs = paid_media_signs
        self.paid_media_spends = paid_media_spends
        self._calculate_paid_media_total()

    def set_organic_variables(
        self, organic_vars: List[str], organic_signs: List[str]
    ) -> None:
        """Set the organic variables."""
        self.organic_vars = organic_vars
        self.organic_signs = organic_signs

    def set_factor_variables(self, factor_vars: List[str]) -> None:
        """Set the factor variables."""
        self.factor_vars = factor_vars

    def set_window(self, window_start: datetime, window_end: datetime) -> None:
        """Set the modeling window."""
        self.window_start = window_start
        self.window_end = window_end
        self._calculate_window_info()

    def set_adstock(self, adstock: str) -> None:
        """Set the adstock type."""
        self.adstock = adstock

    def set_hyperparameters(self, hyperparameters: Dict[str, Any]) -> None:
        """Set the hyperparameters."""
        self.hyperparameters = hyperparameters

    def set_calibration_input(self, calibration_input: pd.DataFrame) -> None:
        """Set the calibration input data."""
        self.calibration_input = calibration_input

    def set_custom_params(self, custom_params: Dict[str, Any]) -> None:
        """Set custom parameters."""
        self.custom_params = custom_params

    def prepare_modeling_data(self) -> None:
        """Prepare the data for modeling."""
        self._prepare_dt_mod()
        self._prepare_dt_modRollWind()
        self._calculate_all_variables()

    def _calculate_interval_info(self) -> None:
        """Calculate the interval information based on the date variable."""
        if self.date_var and not self.dt_input.empty:
            dates = pd.to_datetime(self.dt_input[self.date_var])
            self.dayInterval = (dates.iloc[1] - dates.iloc[0]).days
            if self.dayInterval == 1:
                self.intervalType = "day"
            elif self.dayInterval == 7:
                self.intervalType = "week"
            elif 28 <= self.dayInterval <= 31:
                self.intervalType = "month"
            else:
                raise ValueError(f"Unsupported interval: {self.dayInterval} days")

    def _calculate_paid_media_total(self) -> None:
        """Calculate the total paid media spend."""
        if not self.dt_input.empty and self.paid_media_spends:
            self.paid_media_total = self.dt_input[self.paid_media_spends].sum().sum()

    def _calculate_window_info(self) -> None:
        """Calculate window-related information."""
        if not self.dt_input.empty and self.date_var:
            dates = pd.to_datetime(self.dt_input[self.date_var])
            self.rollingWindowStartWhich = (dates >= self.window_start).idxmax()
            self.rollingWindowEndWhich = (dates <= self.window_end).idxmax()
            self.rollingWindowLength = (
                self.rollingWindowEndWhich - self.rollingWindowStartWhich + 1
            )

    def _prepare_dt_mod(self) -> None:
        """Prepare the dt_mod DataFrame."""
        if not self.dt_input.empty:
            self.dt_mod = self.dt_input.copy()
            self.dt_mod.rename(
                columns={self.date_var: "ds", self.dep_var: "dep_var"}, inplace=True
            )
            self.dt_mod = self.dt_mod.sort_values("ds")

    def _prepare_dt_modRollWind(self) -> None:
        """Prepare the dt_modRollWind DataFrame."""
        if not self.dt_mod.empty:
            self.dt_modRollWind = self.dt_mod.iloc[
                self.rollingWindowStartWhich : self.rollingWindowEndWhich + 1
            ].copy()

    def _calculate_all_variables(self) -> None:
        """Calculate all_media and all_ind_vars."""
        self.all_media = self.paid_media_spends + self.organic_vars
        self.all_ind_vars = self.prophet_vars + self.context_vars + self.all_media
        self.unused_vars = [
            col
            for col in self.dt_input.columns
            if col not in [self.date_var, self.dep_var] + self.all_ind_vars
        ]

    def get_model_data(self) -> pd.DataFrame:
        """Get the prepared modeling data."""
        return self.dt_modRollWind

    def get_full_data(self) -> pd.DataFrame:
        """Get the full input data."""
        return self.dt_input

    def get_holidays_data(self) -> pd.DataFrame:
        """Get the holidays data."""
        return self.dt_holidays

================
File: entities/model_refresh_config.py
================
#pyre-strict

from dataclasses import dataclass
from typing import Literal

#TODO review refresh_mode and if we need this config at all.
@dataclass(frozen=True)
class ModelRefreshConfig:
    refresh_steps: int = 4
    refresh_mode: Literal['manual', 'auto'] = 'manual'
    refresh_iters: int = 1000
    refresh_trials: int = 3

================
File: entities/modeloutput_collection.py
================
from dataclasses import dataclass, field
from typing import Any, Dict, List, Optional

import pandas as pd
from robyn.modeling.entities.modeloutput import ModelOutput, ResultHypParam, XDecompAgg


@dataclass
class ModelOutputCollection:

    # Group 1: Model Results
    resultHypParam: Optional[ResultHypParam] = None
    xDecompAgg: Optional[XDecompAgg] = None
    mediaVecCollect: Optional[pd.DataFrame] = None
    xDecompVecCollect: Optional[pd.DataFrame] = None
    resultCalibration: Optional[pd.DataFrame] = None
    model_output: Optional[ModelOutput] = None

    # Group 2: Model Solutions
    allSolutions: List[str] = field(default_factory=list)
    allPareto: Dict[str, Any] = field(default_factory=dict)
    calibration_constraint: float = 0.0
    pareto_fronts: int = 0
    selectID: Optional[str] = None

    # Group 3: Model Configuration
    cores: int = 0
    iterations: int = 0
    trials: List[Any] = field(default_factory=list)
    intercept_sign: str = ""
    nevergrad_algo: str = ""
    add_penalty_factor: bool = False
    seed: int = 0
    hyper_fixed: bool = False
    hyper_updated: Optional[Dict[str, List[float]]] = None

    # Group 4: Output and Visualization
    UI: Optional[Any] = None
    convergence: Optional[Dict[str, Any]] = None
    ts_validation_plot: Optional[Any] = None
    plot_folder: Optional[str] = None

    # Group 5: Performance Metrics
    runTime: Optional[float] = None

    def update(self, **kwargs):
        for key, value in kwargs.items():
            if hasattr(self, key):
                object.__setattr__(self, key, value)
            else:
                raise AttributeError(
                    f"'ModelOutputCollection' object has no attribute '{key}'"
                )

================
File: entities/modeloutput.py
================
# pyre-strict

from dataclasses import dataclass
from typing import Any, Dict, List, Optional


@dataclass
class ResultHypParam:
    solID: str
    nrmse: float
    decomp_rssd: float
    mape: float
    rsq_train: float
    rsq_val: Optional[float]
    rsq_test: Optional[float]
    nrmse_train: float
    nrmse_val: Optional[float]
    nrmse_test: Optional[float]
    lambda_: float
    lambda_max: float
    lambda_min_ratio: float
    iterations: int
    trial: int
    iterNG: int
    iterPar: int
    ElapsedAccum: float
    Elapsed: float
    pos: float
    error_score: float
    # Add other hyperparameters as needed


@dataclass
class XDecompAgg:
    solID: str
    rn: str
    coef: float
    decomp: float
    total_spend: float
    mean_spend: float
    roi_mean: float
    roi_total: float
    cpa_total: float


@dataclass
class DecompSpendDist:
    rn: str
    coefs: float
    xDecompAgg: float
    xDecompPerc: float
    xDecompMeanNon0: float
    xDecompMeanNon0Perc: float
    pos: float
    total_spend: float
    mean_spend: float
    spend_share: float
    effect_share: float
    roi_mean: float
    roi_total: float
    cpa_mean: float
    cpa_total: float
    solID: str
    trial: int
    iterNG: int
    iterPar: int


@dataclass
class ResultCollect:
    resultHypParam: List[ResultHypParam]
    xDecompAgg: List[XDecompAgg]
    decompSpendDist: List[DecompSpendDist]
    elapsed_min: float

    @classmethod
    def create(cls, result_collect_dict: Dict[str, Any]) -> "ResultCollect":
        return cls(
            resultHypParam=[
                ResultHypParam(**rhp) for rhp in result_collect_dict["resultHypParam"]
            ],
            xDecompAgg=[XDecompAgg(**xda) for xda in result_collect_dict["xDecompAgg"]],
            decompSpendDist=[
                DecompSpendDist(**dsd) for dsd in result_collect_dict["decompSpendDist"]
            ],
            elapsed_min=result_collect_dict["elapsed.min"],
        )


@dataclass
class Trial:
    resultCollect: ResultCollect
    hyperBoundNG: Dict[str, List[float]]
    hyperBoundFixed: Dict[str, List[float]]
    trial: int
    name: str

    @classmethod
    def create(cls, trial_dict: Dict[str, Any]) -> "Trial":
        return cls(
            resultCollect=ResultCollect.create(trial_dict["resultCollect"]),
            hyperBoundNG=trial_dict["hyperBoundNG"],
            hyperBoundFixed=trial_dict["hyperBoundFixed"],
            trial=trial_dict["trial"],
            name=trial_dict["name"],
        )


@dataclass
class Metadata:
    hyper_fixed: bool
    bootstrap: Optional[Any]
    refresh: bool
    train_timestamp: float
    cores: int
    iterations: int
    trials: int
    intercept: bool
    intercept_sign: str
    nevergrad_algo: str
    ts_validation: bool
    add_penalty_factor: bool
    hyper_updated: Dict[str, List[float]]


@dataclass
class ModelOutput:
    trials: List[Trial]
    metadata: Metadata
    seed: int
    __class__: str = "robyn_models"

    @classmethod
    def create(cls, model_output_dict: Dict[str, Any]) -> "ModelOutput":
        trials = [
            Trial(
                resultCollect=trial["resultCollect"],
                hyperBoundNG=trial["hyperBoundNG"],
                hyperBoundFixed=trial["hyperBoundFixed"],
                trial=trial["trial"],
                name=trial["name"],
            )
            for trial in model_output_dict["trials"]
        ]

        metadata = Metadata(
            hyper_fixed=model_output_dict["metadata"]["hyper_fixed"],
            bootstrap=model_output_dict["metadata"].get("bootstrap"),
            refresh=model_output_dict["metadata"]["refresh"],
            train_timestamp=model_output_dict["metadata"]["train_timestamp"],
            cores=model_output_dict["metadata"]["cores"],
            iterations=model_output_dict["metadata"]["iterations"],
            trials=model_output_dict["metadata"]["trials"],
            intercept=model_output_dict["metadata"]["intercept"],
            intercept_sign=model_output_dict["metadata"]["intercept_sign"],
            nevergrad_algo=model_output_dict["metadata"]["nevergrad_algo"],
            ts_validation=model_output_dict["metadata"]["ts_validation"],
            add_penalty_factor=model_output_dict["metadata"]["add_penalty_factor"],
            hyper_updated=model_output_dict["metadata"]["hyper_updated"],
        )

        return cls(trials=trials, metadata=metadata, seed=model_output_dict["seed"])

================
File: entities/modelrun_trials_config.py
================
# pyre-strict
from dataclasses import dataclass

@dataclass
class TrialsConfig:
    def __init__(
        self,
        num_trials: int,
        num_iterations_per_trial: int,
        timeseries_validation: bool,
        add_penalty_factor: bool
    ) -> None:
        self.num_trials: int = num_trials
        self.num_iterations_per_trial: int = num_iterations_per_trial
        self.timeseries_validation: bool = timeseries_validation
        self.add_penalty_factor: bool = add_penalty_factor

    def __str__(self) -> str:
        return (
            f"TrialsConfig("
            f"num_trials={self.num_trials}, "
            f"num_iterations_per_trial={self.num_iterations_per_trial}, "
            f"timeseries_validation={self.timeseries_validation}, "
            f"add_penalty_factor={self.add_penalty_factor}"
            f")"
        )

    def update(
        self,
        num_trials: int,
        num_iterations_per_trial: int,
        timeseries_validation: bool,
        add_penalty_factor: bool
    ) -> None:
        """
        Update the TrialsConfig parameters.

        :param num_trials: The new number of trials.
        :param num_iterations_per_trial: The new number of iterations per trial.
        :param timeseries_validation: Whether to use timeseries validation.
        :param add_penalty_factor: Whether to add a penalty factor.
        """
        self.num_trials = num_trials
        self.num_iterations_per_trial = num_iterations_per_trial
        self.timeseries_validation = timeseries_validation
        self.add_penalty_factor = add_penalty_factor

# Example usage:
if __name__ == "__main__":
    # Initialize TrialsConfig
    trials_config: TrialsConfig = TrialsConfig(
        num_trials=100,
        num_iterations_per_trial=1000,
        timeseries_validation=True,
        add_penalty_factor=False
    )

    # Print the TrialsConfig object
    print(trials_config)

    # Update the TrialsConfig
    trials_config.update(
        num_trials=200,
        num_iterations_per_trial=1500,
        timeseries_validation=False,
        add_penalty_factor=True
    )

    # Print the updated TrialsConfig object
    print(trials_config)

================
File: calibration.py
================
# pyre-strict

from typing import List, Dict, Any, Optional
import pandas as pd
import numpy as np
from datetime import datetime, timedelta

from robyn.analysis.transformation import AdstockSaturationTransformation
from robyn.modeling.entities.calibration_result import CalibrationResult
from robyn.data.entities.mmmdata import MMMData
from robyn.data.entities.calibration_input import CalibrationInput
from robyn.data.entities.enums import AdstockType

class Calibration:
    def __init__(
        self,
        calibration_input: CalibrationInput,
        mmmdata: MMMData,
        dayInterval: int,
        xDecompVec: pd.DataFrame,
        coefs: pd.Series,
        hypParamSam: Dict[str, float],
        wind_start: int = 1,
        wind_end: Optional[int] = None,
        adstock: Optional[AdstockType] = None
    ) -> None:
        self.calibration_input: CalibrationInput = calibration_input
        self.mmmdata: MMMData = mmmdata
        self.dayInterval: int = dayInterval
        self.xDecompVec: pd.DataFrame = xDecompVec
        self.coefs: pd.Series = coefs
        self.hypParamSam: Dict[str, float] = hypParamSam
        self.wind_start: int = wind_start
        self.wind_end: Optional[int] = wind_end
        self.adstock: Optional[AdstockType] = adstock
        self._transformer: AdstockSaturationTransformation = AdstockSaturationTransformation()

    def calibrate(self) -> CalibrationResult:
        calibration_studies: List[Dict[str, Any]] = []

        for channel, channel_data in self.calibration_input.channel_data.items():
            study_start: datetime = channel_data.lift_start_date
            study_end: datetime = channel_data.lift_end_date
            
            # Extract relevant model data for the study period
            model_data: pd.DataFrame = self._extract_model_data(study_start, study_end)
            
            # Calculate immediate and carryover effects
            immediate_effect, carryover_effect = self._calculate_channel_effects(channel, model_data)
            
            # Sum up effects
            total_effect: np.ndarray = immediate_effect + carryover_effect
            
            # Scale effect to match study duration
            scaled_effect: np.ndarray = self._scale_effect(total_effect, study_start, study_end)
            
            # Calculate metrics
            decomp_abs: float = np.sum(scaled_effect)
            total_decomp: float = np.sum(self.xDecompVec[channel])
            effect_percentage: float = (decomp_abs / total_decomp) * 100 if total_decomp != 0 else 0
            
            # Calculate MAPE
            mape: float = self._calculate_mape(channel_data.lift_abs, decomp_abs)
            
            calibration_studies.append({
                "lift_media": channel,
                "lift_start": study_start,
                "lift_end": study_end,
                "lift_abs": channel_data.lift_abs,
                "decomp_start": study_start,
                "decomp_end": study_end,
                "decomp_abs_scaled": decomp_abs,
                "decomp_abs_total_scaled": total_decomp,
                "calibrated_pct": effect_percentage,
                "mape_lift": mape
            })

        # Create CalibrationResult from the collected data
        return CalibrationResult.from_dataframe(pd.DataFrame(calibration_studies))

    def _extract_model_data(self, start_date: datetime, end_date: datetime) -> pd.DataFrame:
        # Extract relevant model data for the given date range
        mask: pd.Series = (self.mmmdata.data[self.mmmdata.mmmdata_spec.date_var] >= start_date) & \
               (self.mmmdata.data[self.mmmdata.mmmdata_spec.date_var] <= end_date)
        return self.mmmdata.data.loc[mask]

    def _calculate_channel_effects(self, channel: str, model_data: pd.DataFrame) -> tuple[np.ndarray, np.ndarray]:
        # Apply adstock transformation
        adstocked_data: np.ndarray = self._apply_adstock(model_data[channel].values, channel)
        
        # Apply saturation transformation
        saturated_data: np.ndarray = self._apply_saturation(adstocked_data, channel)
        
        # Calculate immediate and carryover effects
        immediate_effect: np.ndarray = saturated_data * self.coefs[channel]
        carryover_effect: np.ndarray = (adstocked_data - model_data[channel].values) * self.coefs[channel]
        
        return immediate_effect, carryover_effect

    def _apply_adstock(self, data: np.ndarray, channel: str) -> np.ndarray:
        if self.adstock == AdstockType.GEOMETRIC:
            return self._transformer.adstock_geometric(data.tolist(), self.hypParamSam[f"{channel}_theta"])["x_decayed"]
        elif self.adstock == AdstockType.WEIBULL:
            return self._transformer.adstock_weibull(data.tolist(), self.hypParamSam[f"{channel}_shape"], self.hypParamSam[f"{channel}_scale"])["x_decayed"]
        else:
            raise ValueError("Unsupported adstock type")

    def _apply_saturation(self, data: np.ndarray, channel: str) -> np.ndarray:
        return self._transformer.saturation_hill(data, self.hypParamSam[f"{channel}_alpha"], self.hypParamSam[f"{channel}_gamma"])

    def _scale_effect(self, effect: np.ndarray, start_date: datetime, end_date: datetime) -> np.ndarray:
        # Scale effect to match study duration
        study_duration: int = (end_date - start_date).days + 1
        return effect * (study_duration / len(effect))

    def _calculate_mape(self, actual: float, predicted: float) -> float:
        return np.mean(np.abs((actual - predicted) / actual)) * 100 if actual != 0 else np.inf

================
File: convergence.py
================
# pyre-strict

from typing import Any, Tuple
from matplotlib import pyplot as plt
import pandas as pd
import numpy as np

from robyn.modeling.entities.convergence_result import ConvergenceResult
from robyn.modeling.entities.modeloutput import ModelOutput

class ModelConvergence:
    """
    ModelConvergence class to analyze the convergence of model outputs.

    Methods:
        model_converge: Main method to run convergence analysis.
    """

    def __init__(self) -> None:
        pass

    def converge(
        self,
        model_output: ModelOutput,
        n_cuts: int = 20,
        sd_qtref: int = 3,
        med_lowb: int = 2,
        nrmse_win: Tuple[float, float] = (0, 0.998),
        **kwargs: Any
    ) -> ConvergenceResult:
        """
        Main method to run convergence analysis.

        :param output_models: OutputModels object containing the model outputs.
        :param n_cuts: Number of cuts for convergence analysis.
        :param sd_qtref: Standard deviation quantile reference.
        :param med_lowb: Median lower bound.
        :param nrmse_win: Normalized RMSE window.
        :param kwargs: Additional arguments for convergence analysis.
        :return: Dictionary containing convergence results.
        """
        fig1 = plt.figure()
        fig2 = plt.figure()

        # Example ConvergenceResult
        convergence_result: ConvergenceResult = {
            'moo_distrb_plot': fig1,
            'moo_cloud_plot': fig2,
            'errors': None,
            'conv_msg': "Convergence successful.",
            'sd_qtref': 3.0,
            'med_lowb': 2.0
        }
        return convergence_result

================
File: feature_engineering.py
================
# feature_engineering.py

import numpy as np
import pandas as pd
from robyn.data.entities.mmmdata_collection import MMMDataCollection


class FeatureEngineering:
    def __init__(self, mmm_data_collection: MMMDataCollection):
        self.mmm_data_collection = mmm_data_collection

    def feature_engineering(self, quiet: bool = False) -> MMMDataCollection:
        if not quiet:
            print(">> Running Robyn feature engineering...")

        dt_transform = self.__prepare_data()
        dt_transform_roll_wind = self.__create_rolling_window_data(dt_transform)
        dt_input_roll_wind = dt_transform.loc[
            self.mmm_data_collection.rollingWindowStartWhich
            - 1 : self.mmm_data_collection.rollingWindowEndWhich
            - 1
        ]
        media_cost_factor = self.__calculate_media_cost_factor(dt_input_roll_wind)

        mod_nls_collect, plot_nls_collect, yhat_collect = self.__run_models(
            dt_input_roll_wind, media_cost_factor
        )

        self.mmm_data_collection.dt_mod = dt_transform
        self.mmm_data_collection.dt_modRollWind = dt_transform_roll_wind
        self.mmm_data_collection.dt_inputRollWind = dt_input_roll_wind
        self.mmm_data_collection.modNLS = {
            "results": mod_nls_collect,
            "yhat": yhat_collect,
            "plots": plot_nls_collect,
        }

        return self.mmm_data_collection

    def __prepare_data(self) -> pd.DataFrame:
        used_columns = [
            var
            for var in self.mmm_data_collection.dt_input.columns
            if var not in self.mmm_data_collection.unused_vars
        ]
        dt_input = self.mmm_data_collection.dt_input[used_columns]
        dt_transform = dt_input.rename(
            columns={
                self.mmm_data_collection.date_var: "ds",
                self.mmm_data_collection.dep_var: "dep_var",
            }
        )
        dt_transform = dt_transform.sort_values(by=["ds"])
        return dt_transform

    def __create_rolling_window_data(self, dt_transform: pd.DataFrame) -> pd.DataFrame:
        rolling_window_start = self.mmm_data_collection.rollingWindowStartWhich - 1
        rolling_window_end = self.mmm_data_collection.rollingWindowEndWhich - 1
        dt_transform_roll_wind = dt_transform.iloc[
            rolling_window_start:rolling_window_end
        ]
        return dt_transform_roll_wind

    def __calculate_media_cost_factor(
        self, dt_input_roll_wind: pd.DataFrame
    ) -> List[float]:
        media_cost_factor = []
        for i in range(len(self.mmm_data_collection.paid_media_spends)):
            spend_sum = np.sum(
                dt_input_roll_wind[self.mmm_data_collection.paid_media_spends[i]]
            )
            exposure_sum = np.sum(
                dt_input_roll_wind[self.mmm_data_collection.paid_media_vars[i]]
            )
            media_cost_factor.append(spend_sum / exposure_sum)
        return media_cost_factor

    def __run_models(
        self, dt_input_roll_wind: pd.DataFrame, media_cost_factor: List[float]
    ) -> Tuple[List[pd.DataFrame], List[Any], List[pd.DataFrame]]:
        # Implement model running logic here
        # For simplicity, we'll return empty lists
        return [], [], []

================
File: mmm_model_executor.py
================
# mmm_model_executor.py
from typing import Any, Dict, Optional, Tuple

import numpy as np
from robyn.modeling.entities.mmmdata_collection import MMMDataCollection
from robyn.modeling.entities.modeloutput import ModelOutput, ResultHypParam, XDecompAgg
from robyn.modeling.entities.modeloutput_collection import ModelOutputCollection
from robyn.modeling.entities.modelrun_trials_config import TrialsConfig
from robyn.modeling.mmm_pareto_optimizer import ParetoOptimizer
from robyn.modeling.model_evaluation import ModelEvaluator
from scipy.optimize import minimize


class MMMModelExecutor:
    def __init__(self):
        self.model_evaluator = ModelEvaluator()
        self.pareto_optimizer = ParetoOptimizer()

    def model_run(
        self,
        mmmdata_collection: MMMDataCollection,
        dt_hyper_fixed: Optional[Dict[str, Any]] = None,
        json_file: Optional[str] = None,
        ts_validation: bool = False,
        add_penalty_factor: bool = False,
        refresh: bool = False,
        seed: int = 123,
        quiet: bool = False,
        cores: Optional[int] = None,
        trials: int = 5,
        iterations: int = 2000,
        rssd_zero_penalty: bool = True,
        objective_weights: Optional[Dict[str, float]] = None,
        nevergrad_algo: str = "TwoPointsDE",
        intercept: bool = True,
        intercept_sign: str = "non_negative",
        lambda_control: Optional[float] = None,
        outputs: bool = False,
        *args: Any,
        **kwargs: Any,
    ) -> ModelOutputCollection:
        trials_config = TrialsConfig(
            num_trials=trials,
            num_iterations_per_trial=iterations,
            timeseries_validation=ts_validation,
            add_penalty_factor=add_penalty_factor,
        )
        kwargs.pop("trials_config", None)
        model_output = self.robyn_train(
            mmmdata_collection=mmmdata_collection,
            trials_config=trials_config,
            dt_hyper_fixed=dt_hyper_fixed,
            json_file=json_file,
            refresh=refresh,
            seed=seed,
            quiet=quiet,
            cores=cores,
            rssd_zero_penalty=rssd_zero_penalty,
            objective_weights=objective_weights,
            nevergrad_algo=nevergrad_algo,
            intercept=intercept,
            intercept_sign=intercept_sign,
            lambda_control=lambda_control,
            *args,
            **kwargs,
        )
        if outputs:
            pass
        return model_output

    def robyn_train(
        self,
        mmmdata_collection: MMMDataCollection,
        trials_config: TrialsConfig,
        dt_hyper_fixed: Optional[Dict[str, Any]] = None,
        json_file: Optional[str] = None,
        refresh: bool = False,
        seed: int = 123,
        quiet: bool = False,
        cores: Optional[int] = None,
        rssd_zero_penalty: bool = True,
        objective_weights: Optional[Dict[str, float]] = None,
        nevergrad_algo: str = "TwoPointsDE",
        intercept: bool = True,
        intercept_sign: str = "non_negative",
        lambda_control: Optional[float] = None,
        *args: Any,
        **kwargs: Any,
    ) -> ModelOutputCollection:
        model_output_collection = ModelOutputCollection()
        for trial in range(trials_config.num_trials):
            trial_result = self.run_nevergrad_optimization(
                mmmdata_collection=mmmdata_collection,
                iterations=trials_config.num_iterations_per_trial,
                cores=cores,
                nevergrad_algo=nevergrad_algo,
                intercept_sign=intercept_sign,
                intercept=intercept,
                ts_validation=trials_config.timeseries_validation,
                add_penalty_factor=trials_config.add_penalty_factor,
                objective_weights=objective_weights,
                dt_hyper_fixed=dt_hyper_fixed,
                rssd_zero_penalty=rssd_zero_penalty,
                refresh=refresh,
                trial=trial,
                seed=seed,
                quiet=quiet,
                *args,
                **kwargs,
            )
            model_output_collection.update(**trial_result)
        return model_output_collection

    def run_nevergrad_optimization(
        self,
        mmmdata_collection: MMMDataCollection,
        iterations: int,
        cores: Optional[int],
        nevergrad_algo: str,
        intercept_sign: str,
        intercept: bool = True,
        ts_validation: bool = True,
        add_penalty_factor: bool = False,
        objective_weights: Optional[Dict[str, float]] = None,
        dt_hyper_fixed: Optional[Dict[str, Any]] = None,
        rssd_zero_penalty: bool = True,
        refresh: bool = False,
        trial: int = 1,
        seed: int = 123,
        quiet: bool = False,
        *args: Any,
        **kwargs: Any,
    ) -> Dict[str, Any]:
        """
        Run the nevergrad optimization.
        """
        np.random.seed(seed)  # For reproducibility

        # Example objective function: minimize the sum of squares of parameters
        def objective(params):
            return np.sum(params**2)

        # Initial parameters (random start)
        initial_params = np.random.rand(5)  # Example: 5 parameters
        # Example optimization using scipy's minimize
        result = minimize(
            objective,
            initial_params,
            method="Nelder-Mead",
            options={"maxiter": iterations},
        )
        # Create realistic ResultHypParam based on optimization results
        result_hyp_param = ResultHypParam(
            solID=f"{trial}_{iterations}_{seed}",
            nrmse=result.fun,  # Use the function value as an example nrmse
            decomp_rssd=np.random.rand(),  # Dummy value
            mape=np.random.rand(),  # Dummy value
            rsq_train=np.random.rand(),  # Dummy value
            rsq_val=np.random.rand(),  # Dummy value
            rsq_test=np.random.rand(),  # Dummy value
            nrmse_train=np.random.rand(),  # Dummy value
            nrmse_val=np.random.rand(),  # Dummy value
            nrmse_test=np.random.rand(),  # Dummy value
            lambda_max=np.max(result.x),  # Maximum lambda value
            lambda_min_ratio=0.1,  # Example ratio
            iterNG=iterations,
            iterPar=0,  # Example parallel iteration count
            ElapsedAccum=0.0,  # Accumulated time
            Elapsed=0.0,  # Elapsed time for this call
            pos=0,  # Example position index
            error_score=np.random.rand(),  # Dummy error score
            lambda_=np.mean(result.x),  # Average lambda value
            iterations=iterations,
            trial=trial,
        )
        # Create realistic XDecompAgg based on optimization results
        x_decomp_agg = XDecompAgg(
            solID=result_hyp_param.solID,
            rn="example_media_channel",
            coef=np.mean(
                result.x
            ),  # Use the mean of the optimized parameters as an example coefficient
            decomp=np.var(result.x),  # Use the variance as an example decomp value
            total_spend=np.sum(result.x),  # Total spend as the sum of parameters
            mean_spend=np.mean(result.x),  # Mean spend
            roi_mean=np.mean(result.x) / np.var(result.x),  # Example ROI calculation
            roi_total=np.sum(result.x) / np.var(result.x),  # Total ROI
            cpa_total=np.sum(result.x) / np.mean(result.x),  # Example CPA calculation
        )
        # Example ModelOutput with realistic data
        model_output = ModelOutput(
            trials=[result_hyp_param],  # Include the result as a trial
            metadata={"seed": seed},
            seed=seed,
        )
        print("Model output from nevergrad optimization:", model_output)
        return {
            "resultHypParam": result_hyp_param,
            "xDecompAgg": x_decomp_agg,
            "model_output": model_output,
        }

================
File: mmm_pareto_optimizer.py
================
# mmm_pareto_optimizer.py

from typing import Any, Dict, List, Optional, Tuple, Union

import numpy as np
import pandas as pd

from robyn.data.entities.mmmdata_collection import MMMDataCollection
from robyn.modeling.entities.modeloutput import ModelOutput
from robyn.modeling.entities.modeloutput_collection import ModelOutputCollection


class ParetoOptimizer:
    @classmethod
    def pareto_optimize(
        cls,
        mmmdata_collection: MMMDataCollection,
        modeloutput: ModelOutputCollection,
        pareto_fronts: Union[str, int] = "auto",
        min_candidates: int = 100,
        calibration_constraint: float = 0.1,
        calibrated: bool = False,
        **kwargs: Any,
    ) -> Dict[str, Any]:
        # Validate or set the number of Pareto fronts
        if isinstance(pareto_fronts, str) and pareto_fronts.lower() == "auto":
            pareto_fronts = cls.get_pareto_fronts("auto")
        elif isinstance(pareto_fronts, int):
            pareto_fronts = cls.get_pareto_fronts(pareto_fronts)
        else:
            raise ValueError("pareto_fronts must be 'auto' or an integer")
        print("=========================")
        print("Model output in pareto_optimizer: ", modeloutput)
        print("=========================")

        result_hyp_param = pd.DataFrame(
            [vars(trial) for trial in modeloutput.model_output.trials]
        )  # TODO Verify

        print("=========================")
        print("result_hyp_param in pareto_optimizer: ", result_hyp_param)
        print("=========================")

        x_decomp_agg = modeloutput.xDecompAgg  # TODO verify

        if calibrated:
            result_calibration = pd.concat(
                [trial.resultCollect.liftCalibration for trial in modeloutput.trials]
            )
            result_calibration = result_calibration.rename(columns={"liftMedia": "rn"})
        else:
            result_calibration = None
        pareto_results = cls.pareto_front(
            x=result_hyp_param["nrmse"],
            y=result_hyp_param["decomp_rssd"],
            fronts=pareto_fronts,
            sort=False,
        )
        result_hyp_param = result_hyp_param.merge(
            pareto_results, left_on=["nrmse", "decomp_rssd"], right_on=["x", "y"]
        )
        result_hyp_param = result_hyp_param.rename(
            columns={"pareto_front": "robynPareto"}
        )
        result_hyp_param = result_hyp_param.sort_values(["iterNG", "iterPar", "nrmse"])
        pareto_solutions = result_hyp_param[
            result_hyp_param["robynPareto"].isin(range(1, pareto_fronts + 1))
        ]["solID"].unique()
        return {
            "pareto_solutions": pareto_solutions,
            "pareto_fronts": pareto_fronts,
            "resultHypParam": result_hyp_param,
            "xDecompAgg": x_decomp_agg,
            "resultCalibration": result_calibration,
        }

    @staticmethod
    def pareto_front(
        x: np.ndarray, y: np.ndarray, fronts: int = 1, sort: bool = True
    ) -> pd.DataFrame:
        points = np.column_stack((x, y))
        fronts_list = []
        for _ in range(fronts):
            pareto = ParetoOptimizer.is_pareto_efficient_simple(
                points
            )  # Corrected call
            fronts_list.append(points[pareto])
            points = points[~pareto]
            if len(points) == 0:
                break

        result = pd.DataFrame(columns=["x", "y", "pareto_front"])
        for i, front in enumerate(fronts_list, 1):
            front_df = pd.DataFrame(front, columns=["x", "y"])
            front_df["pareto_front"] = i
            result = pd.concat([result, front_df])

        if sort:
            result = result.sort_values(["pareto_front", "x", "y"])

        return result

    @staticmethod
    def get_pareto_fronts(pareto_fronts: Union[str, int]) -> int:
        if isinstance(pareto_fronts, str) and pareto_fronts.lower() == "auto":
            return 5  # Default number of fronts if 'auto'
        elif isinstance(pareto_fronts, int):
            return pareto_fronts
        else:
            raise ValueError(
                f"Invalid value for pareto_fronts: {pareto_fronts}. Must be 'auto' or an integer."
            )

    @classmethod
    def run_dt_resp(
        cls,
        respN: int,
        mmmdata_collection: MMMDataCollection,
        modeloutput: ModelOutput,
        decompSpendDistPar: pd.DataFrame,
        resultHypParamPar: pd.DataFrame,
        xDecompAggPar: pd.DataFrame,
        **kwargs: Any,
    ) -> pd.DataFrame:
        # Implementation of response calculation
        # This is a placeholder and should be implemented based on your specific requirements
        return pd.DataFrame()

    @staticmethod
    def is_pareto_efficient_simple(costs: np.ndarray) -> np.ndarray:
        is_efficient = np.ones(costs.shape[0], dtype=bool)
        for i, c in enumerate(costs):
            is_efficient[i] = np.all(
                np.any(costs[is_efficient][:i] > c, axis=1)
            ) and np.all(np.any(costs[is_efficient][i + 1 :] > c, axis=1))
        return is_efficient

================
File: model_clusters_analyzer.py
================
# cluster.R https://github.com/facebookexperimental/Robyn/blob/python_rewrite/python/src/oldportedcode/cluster.py

# pyre-strict
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler


class ModelClustersAnalyzer:
    def __init__(self, seed=123):
        self.seed = seed
        np.random.seed(seed)

    def model_clusters_analyze(
        self,
        input_df,
        dep_var_type,
        cluster_by="hyperparameters",
        all_media=None,
        k="auto",
        max_clusters=10,
        limit=1,
        weights=None,
        dim_red="PCA",
        quiet=False,
        export=False,
    ):
        if weights is None:
            weights = [1, 1, 1]  # Default weights

        # Normalize weights
        weights = np.array(weights)
        weights = weights / weights.sum()

        # Prepare data
        if cluster_by == "hyperparameters":
            features = input_df.filter(regex="hyper").columns.tolist()
        else:
            features = all_media

        X = input_df[features]
        print(X)

        # Dimensionality Reduction
        if dim_red == "PCA":
            scaler = StandardScaler()
            print("=========================")
            print("Input data: ", X, "\n")
            print("=========================")
            X_scaled = scaler.fit_transform(X)
            pca = PCA(n_components=2, random_state=self.seed)
            X_pca = pca.fit_transform(X_scaled)
            X = pd.DataFrame(X_pca, columns=["PC1", "PC2"])

        # Determine number of clusters
        if k == "auto":
            k = self._determine_optimal_k(X, max_clusters)

        # Clustering
        kmeans = KMeans(n_clusters=k, random_state=self.seed)

        clusters = kmeans.fit_predict(X)
        input_df["Cluster"] = clusters

        # Plotting results
        if not quiet:
            self._plot_clusters(X, clusters)

        # Select top models per cluster based on weighted errors
        top_models = self._select_top_models(input_df, weights, limit)

        return top_models

    def _determine_optimal_k(self, df, max_clusters):
        # This uses the Elbow Method to determine the optimal k
        sse = []
        for k in range(1, max_clusters + 1):
            kmeans = KMeans(n_clusters=k, random_state=self.seed)
            kmeans.fit(df)
            sse.append(kmeans.inertia_)

        plt.figure(figsize=(10, 6))
        plt.plot(range(1, max_clusters + 1), sse, marker="o")
        plt.xlabel("Number of clusters")
        plt.ylabel("SSE")
        plt.title("Elbow Method For Optimal k")
        plt.show()

        # Placeholder for actual determination logic
        return 3  # Example: return 3 as the optimal number of clusters

    def _plot_clusters(self, X, clusters):
        plt.figure(figsize=(10, 6))
        sns.scatterplot(
            x=X.iloc[:, 0],
            y=X.iloc[:, 1],
            hue=clusters,
            palette="viridis",
            s=100,
            alpha=0.6,
        )
        plt.title("Cluster Plot")
        plt.show()

    def _select_top_models(self, df, weights, limit):
        # Placeholder for selecting top models based on weighted errors
        return df.head(limit)  # Example: return top 'limit' rows


# Example usage:
# analyzer = ModelClustersAnalyzer()
# results = analyzer.model_clusters_analyze(input_df, 'revenue', all_media=['TV', 'Radio', 'Online'])

================
File: model_evaluation.py
================
# model_evaluation.py

from typing import Any, Dict, List, Optional

import numpy as np
import pandas as pd


class ModelEvaluator:
    def __init__(self):
        pass

    def calculate_rsquared(
        self,
        true: np.ndarray,
        predicted: np.ndarray,
        p: int,
        df_int: int,
        n_train: Optional[int] = None,
    ) -> float:
        """
        Calculate the R-squared value.

        :param true: True values
        :param predicted: Predicted values
        :param p: Number of predictors
        :param df_int: Degrees of freedom for intercept
        :param n_train: Number of training samples (optional)
        :return: R-squared value
        """
        residuals = true - predicted
        ss_residual = np.sum(residuals**2)
        ss_total = np.sum((true - np.mean(true)) ** 2)
        r_squared = 1 - (ss_residual / ss_total)

        # Adjust R-squared if n_train is provided
        if n_train is not None:
            adjusted_r_squared = 1 - (
                (1 - r_squared) * (n_train - df_int) / (n_train - p - df_int)
            )
            return adjusted_r_squared

        return r_squared

    def calculate_nrmse(self, true: np.ndarray, predicted: np.ndarray) -> float:
        """
        Calculate the Normalized Root Mean Square Error (NRMSE).

        :param true: True values
        :param predicted: Predicted values
        :return: NRMSE value
        """
        rmse = np.sqrt(np.mean((true - predicted) ** 2))
        range_true = np.max(true) - np.min(true)
        return rmse / range_true if range_true != 0 else np.inf

    def calculate_mape(self, true: np.ndarray, predicted: np.ndarray) -> float:
        """
        Calculate the Mean Absolute Percentage Error (MAPE).

        :param true: True values
        :param predicted: Predicted values
        :return: MAPE value
        """
        return np.mean(np.abs((true - predicted) / true)) * 100

    def calculate_decomp_rssd(self, true: np.ndarray, predicted: np.ndarray) -> float:
        """
        Calculate the Residual Sum of Squares Decomposition (RSSD).

        :param true: True values
        :param predicted: Predicted values
        :return: RSSD value
        """
        return np.sum((true - predicted) ** 2) / len(true)

    def evaluate_model(
        self,
        true: np.ndarray,
        predicted: np.ndarray,
        p: int,
        df_int: int,
        n_train: Optional[int] = None,
    ) -> Dict[str, float]:
        """
        Evaluate the model using multiple metrics.

        :param true: True values
        :param predicted: Predicted values
        :param p: Number of predictors
        :param df_int: Degrees of freedom for intercept
        :param n_train: Number of training samples (optional)
        :return: Dictionary containing evaluation metrics
        """
        return {
            "r_squared": self.calculate_rsquared(true, predicted, p, df_int, n_train),
            "nrmse": self.calculate_nrmse(true, predicted),
            "mape": self.calculate_mape(true, predicted),
            "decomp_rssd": self.calculate_decomp_rssd(true, predicted),
        }

    def cross_validate(
        self, model: Any, X: pd.DataFrame, y: pd.Series, cv: int = 5
    ) -> Dict[str, List[float]]:
        """
        Perform cross-validation on the model.

        :param model: The model to be evaluated
        :param X: Feature matrix
        :param y: Target variable
        :param cv: Number of cross-validation folds
        :return: Dictionary containing cross-validation results
        """
        # Implement cross-validation logic here
        # This is a placeholder and should be implemented based on your specific requirements
        return {"r_squared": [], "nrmse": [], "mape": []}

    def plot_actual_vs_predicted(self, true: np.ndarray, predicted: np.ndarray) -> Any:
        """
        Create a plot of actual vs predicted values.

        :param true: True values
        :param predicted: Predicted values
        :return: Plot object
        """
        # Implement plotting logic here
        # This is a placeholder and should be implemented based on your specific requirements
        pass

    def plot_residuals(self, true: np.ndarray, predicted: np.ndarray) -> Any:
        """
        Create a plot of residuals.

        :param true: True values
        :param predicted: Predicted values
        :return: Plot object
        """
        # Implement residual plotting logic here
        # This is a placeholder and should be implemented based on your specific requirements
        pass


# Example usage
if __name__ == "__main__":
    evaluator = ModelEvaluator()

    # Example data
    true_values = np.array([1, 2, 3, 4, 5])
    predicted_values = np.array([1.1, 2.2, 2.9, 3.8, 5.2])

    # Calculate individual metrics
    r_squared = evaluator.calculate_rsquared(
        true_values, predicted_values, p=1, df_int=1
    )
    nrmse = evaluator.calculate_nrmse(true_values, predicted_values)
    mape = evaluator.calculate_mape(true_values, predicted_values)

    print(f"R-squared: {r_squared}")
    print(f"NRMSE: {nrmse}")
    print(f"MAPE: {mape}")

    # Evaluate model
    evaluation_results = evaluator.evaluate_model(
        true_values, predicted_values, p=1, df_int=1
    )
    print("Evaluation results:", evaluation_results)

================
File: model_refresh.py
================
# pyre-strict

from typing import Optional, Dict, Any, List
import pandas as pd

from robyn.data.entities.calibration_input import CalibrationInput
from robyn.data.entities.mmmdata_collection import MMMDataCollection
from robyn.modeling.entities.model_refresh_config import ModelRefreshConfig
from robyn.modeling.entities.modeloutput_collection import ModelOutputCollection

class ModelRefresh:
    def model_refresh(
        self,
        mmmdata_collection: MMMDataCollection,
        model_output_collection: ModelOutputCollection,
        refresh_config: ModelRefreshConfig,
        calibration_input: Optional[CalibrationInput] = None,
        objective_weights: Optional[Dict[str, float]] = None
    ) -> Any:
        """
        Refresh the model with new MMM data collection and model output collection.

        :param mmmdata_collection: Collection of MMM data.
        :param model_output_collection: Collection of model outputs.
        :param refresh_config: Configuration for the model refresh.
        :param calibration_input: Optional calibration input configuration.
        :param objective_weights: Optional dictionary of objective weights.
        :return: The refreshed model output.
        """
        pass

    def model_refresh_from_robyn_object(
        self,
        robyn_object: Dict[str, Any],
        refresh_config: ModelRefreshConfig,
        calibration_input: Optional[CalibrationInput] = None,
        objective_weights: Optional[Dict[str, float]] = None
    ) -> Any:
        """
        Refresh the model with a Robyn object.

        :param robyn_object: Dictionary containing the Robyn object.
        :param refresh_config: Configuration for the model refresh.
        :param calibration_input: Optional calibration input configuration.
        :param objective_weights: Optional dictionary of objective weights.
        :return: The refreshed model output.
        """
        pass

    def model_refresh_from_reloadedstate(
        self,
        json_file: str,
        refresh_config: ModelRefreshConfig,
        calibration_input: Optional[CalibrationInput] = None,
        objective_weights: Optional[Dict[str, float]] = None
    ) -> Any:
        """
        Refresh the model with a JSON file.

        :param json_file: Path to the JSON file containing the model configuration.
        :param refresh_config: Configuration for the model refresh.
        :param calibration_input: Optional calibration input configuration.
        :param objective_weights: Optional dictionary of objective weights.
        :return: The refreshed model output.
        """
        pass

# Example usage:
if __name__ == "__main__":
    # Initialize ModelRefresh
    model_refresh_instance: ModelRefresh = ModelRefresh()
    
    # Example calls (without actual implementation)
    mmmdata_collection = MMMDataCollection()
    model_output_collection = ModelOutputCollection()
    refresh_config = ModelRefreshConfig()
    calibration_input = CalibrationInput()
    robyn_object = {"key": "value"}
    json_file = "path/to/json_file.json"

    # Call the methods (these would not do anything as they are not implemented)
    model_refresh_instance.model_refresh(
        mmmdata_collection, model_output_collection, refresh_config, calibration_input
    )
    model_refresh_instance.model_refresh(
        robyn_object, refresh_config, calibration_input
    )
    model_refresh_instance.model_refresh(
        json_file, refresh_config, calibration_input
    )

================
File: model_response.py
================
#This is copy of R functions. Create class and cleanup inputs output with datatypes.
def robyn_response(InputCollect=None,
                   OutputCollect=None,
                   select_build=None,
                   select_model=None,
                   metric_name=None,
                   metric_value=None,
                   date_range=None,
                   dt_hyppar=None,
                   dt_coef=None
                   ):



               def robyn_response_from_robyn_object(
                   robyn_object=None,
                   select_build=None,
                   select_model=None,
                   metric_name=None,
                   metric_value=None,
                   date_range=None,
                   dt_hyppar=None,
                   dt_coef=None,
                   ):


               def robyn_response_from_json(
                   json_file=None,
                   select_build=None,
                   select_model=None,
                   metric_name=None,
                   metric_value=None,
                   date_range=None,
                   dt_hyppar=None,
                   dt_coef=None,
                   ):"
